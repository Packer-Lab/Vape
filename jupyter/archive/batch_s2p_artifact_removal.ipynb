{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ipython magic\n",
    "%reset -f\n",
    "%matplotlib notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general imports\n",
    "import sys\n",
    "sys.path.append(r'C:\\Users\\Robert Lees\\Documents\\Code\\Vape\\suite2p_etc')\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\suite2p']\n"
     ]
    }
   ],
   "source": [
    "#notebook specific imports\n",
    "from utils.gsheets_importer import gsheet2df, correct_behaviour_df, split_df, path_conversion, path_finder\n",
    "from utils.artifact_removal import artifact_removal\n",
    "from utils.utils_funcs import *\n",
    "from utils.paq2py import *\n",
    "import tifffile\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import suite2p\n",
    "print(suite2p.__path__)\n",
    "from suite2p.run_s2p import run_s2p\n",
    "from settings import ops\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P:rlees\\\\Data\\\\2019-03-12\\\\RL025\\\\2019-03-12_RL025_t-007\\\\MPTIFF',\n",
       " 'P:aharris\\\\Data\\\\2019-04-11\\\\2019-04-11_RL025_t-006',\n",
       " 'P:aharris\\\\Data\\\\2019-04-11\\\\2019-04-11_RL025_t-007',\n",
       " 'P:aharris\\\\Data\\\\2019-04-11\\\\2019-04-11_RL025_t-008',\n",
       " 'P:aharris\\\\Data\\\\2019-04-11\\\\2019-04-11_RL025_t-009']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read g sheets to populate some lists for processing stim artifact and running suite2p\n",
    "\n",
    "sheet_ID = '1Z9CvuA1qlLsB0Gar48bkZscLhtlP9iIWk4PYZur8cvc'\n",
    "SHEET_NAME = '2019-05-23_artifact_removal_s2p'\n",
    "df = gsheet2df(sheet_ID, HEADER_ROW=4, SHEET_NAME=SHEET_NAME)\n",
    "\n",
    "# at this point we have lots of files that could be whisker stim or photostim, need to find out which is which\n",
    "\n",
    "for_processing = split_df(df, 's2p_me') # only files with TRUE in suite2p_me column\n",
    "\n",
    "if not for_processing.shape[0]:\n",
    "    raise Exception('ERROR: no files set for processing')\n",
    "\n",
    "stim = for_processing.loc[:,'stim'] # find out what stims have been carried out\n",
    "photostim_idx = [i for i,stim in enumerate(stim) if stim=='p'] # row indices of all photostim exps (for artifact removal)\n",
    "whisker_stim_idx = [i for i,stim in enumerate(stim) if stim=='w'] # '' for whisker stim (no artifact removal)\n",
    "\n",
    "if ( len(photostim_idx) + len(whisker_stim_idx) ) != stim.shape[0]:\n",
    "    raise Exception('ERROR: stim type is not defined for some files')\n",
    "\n",
    "tiff_paths = for_processing.loc[:,'tiff_path']\n",
    "paq_paths = for_processing.loc[:,'paq_path']\n",
    "\n",
    "if not all(tiff_paths) or not all(paq_paths):\n",
    "    raise Exception('ERROR: missing tiff or paq paths')\n",
    "    \n",
    "# below is information that will be later required for suite2p and stim removal\n",
    "\n",
    "n_frames = [int(i) for i in list(for_processing.loc[:,'n_frames'])] # for stim removal\n",
    "stim_dur = [int(i) for i in list(for_processing.loc[:,'total_stim_duration'])] # for stim removal\n",
    "n_planes = [int(i) for i in list(for_processing.loc[:,'n_planes'])] # for s2p and stim removal\n",
    "\n",
    "if not all(n_frames) or not all([stim_dur[i] for i in photostim_idx]) or not all(n_planes):\n",
    "    raise Exception('ERROR: missing important metadata for processing')\n",
    "\n",
    "packerstation_path = r\"P:\" # the path to PackerStation on the local machine\n",
    "# TODO: update this to path_finder rather than conversion, to increase failsafe at this point\n",
    "tiffs_pstation = path_conversion(tiff_paths, packerstation_path) # convert paths (from Packer1 or PackerStation) to local PackerStation paths\n",
    "paqs_pstation = path_conversion(paq_paths, packerstation_path)\n",
    "\n",
    "tiffs_pstation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(512, 512), (512, 512), (512, 512), (512, 512), (512, 512)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use first frame of tiffs to find resolution of image, required later for calculating cell diameter in pixels for s2p\n",
    "\n",
    "frame_size = [] \n",
    "\n",
    "for tiff_path in tiffs_pstation:\n",
    "    \n",
    "    frame = np.empty((0))\n",
    "    \n",
    "    if '.tif' in tiff_path or '.tiff' in tiff_path: # the path points directly to a file\n",
    "        \n",
    "        frame = tifffile.imread(tiff_path, key=0) \n",
    "        frame_size.append(frame.shape)\n",
    "        break\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        for item in os.listdir(tiff_path): # the path points to a folder\n",
    "            \n",
    "            if '.tif' in item or '.tiff' in item:\n",
    "                \n",
    "                filename = os.path.join(tiff_path, item)\n",
    "                frame = tifffile.imread(filename, key=0)\n",
    "                frame_size.append(frame.shape)\n",
    "                break\n",
    "                \n",
    "    if len(frame.shape)==1: \n",
    "\n",
    "        print(tiff_path)\n",
    "        raise Exception('ERROR: could not load TIFF file')\n",
    "\n",
    "frame_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:rlees\\Data\\2019-03-12\\RL025\\2019-03-12_RL025_t-007\\MPTIFF\n",
      "P:aharris\\Data\\2019-04-11\\2019-04-11_RL025_t-006\n",
      "P:aharris\\Data\\2019-04-11\\2019-04-11_RL025_t-007\n",
      "P:aharris\\Data\\2019-04-11\\2019-04-11_RL025_t-008\n",
      "P:aharris\\Data\\2019-04-11\\2019-04-11_RL025_t-009\n"
     ]
    }
   ],
   "source": [
    "# obtain list of tiffs to run stim removal on\n",
    "\n",
    "tiff_lists = []\n",
    "\n",
    "# need to find single multi-page TIFF or many TIFFs/MPTIFFs\n",
    "\n",
    "for tiff in tiffs_pstation:\n",
    "    print(tiff)\n",
    "    \n",
    "    if '.tif' not in tiff or '.tiff' not in tiff: # if the path is not directly a TIFF, it may be folder with MPTIFF or multiple TIFFs/MPTIFFs\n",
    "        \n",
    "        items = os.listdir(tiff)\n",
    "        newlist = []\n",
    "        \n",
    "        for name in items:\n",
    "            if name.endswith(\".tiff\") or name.endswith(\".tif\"):\n",
    "                filename = os.path.join(tiff, name)\n",
    "                newlist.append(filename)\n",
    "        tiff_lists.append(newlist)\n",
    "        \n",
    "    else: # if provided path directs to TIFF file, make sure it is only one in folder\n",
    "        \n",
    "        tiff_count = 0\n",
    "        \n",
    "        parent_dir = os.path.dirname(tiff)\n",
    "        items = os.listdir(parent_dir)\n",
    "                \n",
    "        for name in items:\n",
    "            if name.endswith(\".tiff\") or name.endswith(\".tif\"):\n",
    "                tiff_count += 1\n",
    "        \n",
    "        if tiff_count > 1:\n",
    "            raise Exception('ERROR: make sure large, single TIFF files are in their own folder')\n",
    "        else: \n",
    "            tiff_lists.append(tiff)\n",
    "            \n",
    "photostim_tiffs = [tiff_lists[i] for i in photostim_idx] # only run artifact removal-specific code on photostim exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load up paq file and find stim times + start frames\n",
    "\n",
    "remove_frames = []\n",
    "\n",
    "for i,_ in enumerate(photostim_tiffs):\n",
    "    paq = paq_read(paqs_pstation[i])\n",
    "    stim_frames = stim_start_frame(paq, 'markpoints2packio') # TODO: will fail in certain situations where each stim was triggered every time\n",
    "    frame_clock = paq_data(paq, 'frame_clock', threshold_ttl=True)\n",
    "\n",
    "    duration_ms = stim_dur[i] #length of stim\n",
    "    duration_samples = (int(duration_ms) / 1000) * paq['rate']\n",
    "    \n",
    "    # use this to remove frames during stim based on paq\n",
    "    to_remove = []\n",
    "\n",
    "    for stim_frame in stim_frames: \n",
    "\n",
    "        # frame indexes that fall during the stim\n",
    "        in_stim = np.where((frame_clock >= stim_frame) & (frame_clock <= stim_frame + duration_samples))[0]\n",
    "\n",
    "        #empircal observation, these are the frames with artifact\n",
    "        in_stim = np.append(in_stim, in_stim[-1]+1)\n",
    "        in_stim = np.append(in_stim, in_stim[-1]+1)\n",
    "\n",
    "        to_remove.append(in_stim)\n",
    "\n",
    "    remove_frames.append(np.ravel(to_remove))\n",
    "\n",
    "for frames in remove_frames:\n",
    "    print(len(frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load up TIFFs in blocks and run stim removal on them\n",
    "user_block_size = 500 # should be above 100 to work without problems (enough TIFF pages for multiplane thresholding)\n",
    "\n",
    "for i,tiff_list in enumerate(photostim_tiffs): # for each list of TIFFs \n",
    "        \n",
    "    parent_dir = os.path.dirname(tiff_list[0]) # parent directory to create output directory inside of\n",
    "    output_dir = os.path.join(parent_dir, 'Artifact_removed')\n",
    "    print(output_dir)\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(output_dir) # make output directory for artifact removal TIFFs\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    base_path = os.path.splitext(tiff_list[0])[0] # get parent folder of TIFF for saving files\n",
    "    base_filename = os.path.basename(base_path)\n",
    "    print(base_filename)\n",
    "    \n",
    "    substack = np.empty((0,512,512), dtype=np.uint16) # empty np array for appending to\n",
    "    \n",
    "    block_size = myround(user_block_size, base=n_planes[i]) # want the block_size to be in multiples of the number of planes if multiplanar TIFF\n",
    "    \n",
    "    iteration = 0\n",
    "    prev_frames = 0\n",
    "    current_frames = 0\n",
    "    \n",
    "    width_thresh = 5 * (frame_size[i][0] / 512) # currently using 5 pixels as default for 512 image, scaled for other resolution\n",
    "    \n",
    "    if len(tiff_list)>1: # multiple TIFFs or MPTIFFs\n",
    "        print('Multiple TIFF files')\n",
    "        tiff_list = sorted(tiff_list) \n",
    "        \n",
    "        for tiff in tiff_list:\n",
    "            \n",
    "            if '.ome' in tiff and tiff == tiff_list[0]: # sometimes, if it is .ome.tiff, the first file has a header which is mistaken for other pages\n",
    "                temp_tiff = tifffile.imread(tiff, key=0) \n",
    "            else:\n",
    "                temp_tiff = tifffile.imread(tiff)\n",
    "            \n",
    "            if len(temp_tiff.shape) is not 3: # can only append substacks if dimensions match, so match them (should be 3d)\n",
    "                temp_tiff = np.expand_dims(temp_tiff, axis=0)\n",
    "                \n",
    "            substack = np.append(substack, temp_tiff, axis=0)\n",
    "            \n",
    "            if substack.shape[0]>block_size or tiff==tiff_list[-1]: # if substack is large (RAM conservation) or at last TIFF in list, process the stack\n",
    "                \n",
    "                substack_frames = substack.shape[0] # number of frames in current stack\n",
    "                current_frames = substack_frames + prev_frames\n",
    "                remove_me = [frame - prev_frames for frame in remove_frames[i] if prev_frames <= frame < current_frames] # slice the frames to be removed for this substack\n",
    "                \n",
    "                non_stim_frames = [non_stim for non_stim,_ in enumerate(substack) if non_stim not in remove_me]\n",
    "                \n",
    "                try:\n",
    "                    thresh_list = non_stim_frames[:50] # TODO: this will break if <50 frames, not common, but will be towards last block (could be any size)\n",
    "                except:\n",
    "                    if non_stim_frames:\n",
    "                        thresh_list = non_stim_frames\n",
    "                    else:\n",
    "                        raise Exception('ERROR: block contains only stim, cant find baseline')\n",
    "                    \n",
    "                if remove_me:\n",
    "                    substack_processed = artifact_removal(substack, thresh_list=thresh_list, remove_me=remove_me, width_thresh=width_thresh, nplanes=n_planes[i]) # remove artifact\n",
    "                else:\n",
    "                    substack_processed = substack\n",
    "                \n",
    "                filename = base_filename + '_artifactRemoved' + str(iteration) + '.tiff'\n",
    "                output_path = os.path.join(output_dir, filename)\n",
    "                tifffile.imwrite(output_path, substack_processed) # write processed tiff\n",
    "                \n",
    "                substack = np.empty((0,512,512), dtype=np.uint16)\n",
    "                iteration += 1\n",
    "                prev_frames = current_frames # save which frame we are at (for calculating stims to include next time)\n",
    "                    \n",
    "    else: # single, large MPTIFF\n",
    "        print('Single TIFF file')\n",
    "        remaining_frames = n_frames[i]\n",
    "        \n",
    "        while remaining_frames:\n",
    "            \n",
    "            if remaining_frames > block_size: # load a block of TIFF pages unless there are fewer than a block left, should pre-define block according to RAM capacity\n",
    "                current_frames += block_size\n",
    "            else:\n",
    "                current_frames += remaining_frames # load all remaining TIFF pages\n",
    "            \n",
    "            substack = tifffile.imread(tiff_list, key=range(prev_frames, current_frames)) # load in all frames for this block starting from the previous block\n",
    "            \n",
    "            remove_me = [frame - prev_frames for frame in remove_frames[i] if prev_frames <= frame < current_frames] # slice the frames to be removed so they are for this substack only\n",
    "            \n",
    "            non_stim_frames = [non_stim for non_stim,_ in enumerate(substack) if non_stim not in remove_me] # sometimes can't find threshold so find non-stim frames and provide it to artifact removal\n",
    "            thresh_list = non_stim_frames[:50] # list of frames for threshold in artifact removal function\n",
    "            \n",
    "            if remove_me:\n",
    "                substack_processed = artifact_removal(substack, thresh_list=thresh_list, remove_me=remove_me, width_thresh=width_thresh, nplanes=n_planes[i]) # remove artifact\n",
    "            else:\n",
    "                substack_processed = substack # if no frames to be removed\n",
    "                    \n",
    "            filename = base_filename + '_artifactRemoved' + str(iteration) + '.tiff' # construct filename\n",
    "            output_path = os.path.join(output_dir, filename)\n",
    "            tifffile.imwrite(output_path, substack_processed) # write processed tiff\n",
    "            iteration += 1 \n",
    "            prev_frames = current_frames # save progress in terms of frames with artifact removed\n",
    "                        \n",
    "            remaining_frames = n_frames[i] - current_frames # frames remaining to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:rlees\\Data\\2019-03-12\\RL025\\2019-03-12_RL025_t-007\\MPTIFF\\2019-03-12_RL025_t-007_Cycle00001_Ch3.tif\n",
      "Photostim experiment\n",
      "P:aharris\\Data\\2019-04-11\\2019-04-11_RL025_t-006\\2019-04-11_RL025_t-006_Cycle00001_Ch3.tif\n",
      "Photostim experiment\n",
      "P:aharris\\Data\\2019-04-11\\2019-04-11_RL025_t-007\\2019-04-11_RL025_t-007_Cycle00001_Ch3.tif\n",
      "Photostim experiment\n",
      "P:aharris\\Data\\2019-04-11\\2019-04-11_RL025_t-008\\2019-04-11_RL025_t-008_Cycle00001_Ch3.tif\n",
      "Photostim experiment\n",
      "P:aharris\\Data\\2019-04-11\\2019-04-11_RL025_t-009\\2019-04-11_RL025_t-009_Cycle00001_Ch3.tif\n",
      "Photostim experiment\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'data_path': ['P:rlees\\\\Data\\\\2019-03-12\\\\RL025\\\\2019-03-12_RL025_t-007\\\\MPTIFF'],\n",
       "  'fs': 30.0,\n",
       "  'diameter': 11.0,\n",
       "  'batch_size': 500,\n",
       "  'nimg_init': 500,\n",
       "  'nplanes': 1},\n",
       " {'data_path': ['P:aharris\\\\Data\\\\2019-04-11\\\\2019-04-11_RL025_t-006'],\n",
       "  'fs': 30.0,\n",
       "  'diameter': 11.0,\n",
       "  'batch_size': 500,\n",
       "  'nimg_init': 500,\n",
       "  'nplanes': 1},\n",
       " {'data_path': ['P:aharris\\\\Data\\\\2019-04-11\\\\2019-04-11_RL025_t-007'],\n",
       "  'fs': 30.0,\n",
       "  'diameter': 11.0,\n",
       "  'batch_size': 500,\n",
       "  'nimg_init': 500,\n",
       "  'nplanes': 1},\n",
       " {'data_path': ['P:aharris\\\\Data\\\\2019-04-11\\\\2019-04-11_RL025_t-008'],\n",
       "  'fs': 30.0,\n",
       "  'diameter': 11.0,\n",
       "  'batch_size': 500,\n",
       "  'nimg_init': 500,\n",
       "  'nplanes': 1},\n",
       " {'data_path': ['P:aharris\\\\Data\\\\2019-04-11\\\\2019-04-11_RL025_t-009'],\n",
       "  'fs': 30.0,\n",
       "  'diameter': 11.0,\n",
       "  'batch_size': 500,\n",
       "  'nimg_init': 500,\n",
       "  'nplanes': 1}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# important: data paths must be lists even if only one element\n",
    "# can also only run on specified tiffs\n",
    "\n",
    "# sampling rate\n",
    "fps = [float(i) for i in list(for_processing.loc[:,'fps'])]\n",
    "\n",
    "# cell diameter\n",
    "zoom = [float(i) for i in list(for_processing.loc[:,'zoom'])] # for s2p cell diameter calculation\n",
    "\n",
    "user_batch_size = 500 # number of frames to be processed at once (i.e. registered)\n",
    "\n",
    "db = []\n",
    "\n",
    "for i,tiff_list in enumerate(tiff_lists):\n",
    "    print(tiff_list[0])\n",
    "    \n",
    "    if tiff_list in photostim_tiffs: # photostim experiments should have tiffs processed with artifact removed\n",
    "        print('Photostim experiment')\n",
    "        umbrella_folder = os.path.dirname(tiff_list[0])\n",
    "#         folder_name = path_finder(umbrella_folder, 'Artifact_removed',  is_folder=True) # find new folder containing artifact-removed data\n",
    "        folder_name = umbrella_folder\n",
    "    else: # whisker stim experiments\n",
    "        print('Whisker stim experiment')\n",
    "        folder_name = [tiff_list]\n",
    "        \n",
    "#     tiff_list = []\n",
    "    \n",
    "#     for file in os.listdir(folder_name):\n",
    "#             if '.ome' not in file and '.tif' in file:\n",
    "#                 tiff_list.append(file) \n",
    "    \n",
    "#     tiff_list = sorted(tiff_list)\n",
    "\n",
    "    sampling_rate = fps[i]/n_planes[i]\n",
    "    diameter = (5.5 * zoom[i]) * (frame_size[i][0] / 512) # cell is 5.5 pixels in diameter at 1x zoom, multiplied by the resolution scale\n",
    "    batch_size = user_batch_size * (512 / frame_size[i][0] ) # larger frames will be more RAM intensive, scaled user batch size based on 512x512 images\n",
    "      \n",
    "    db.append({ 'data_path' : [folder_name], \n",
    "#               'tiff_list' : tiff_list,\n",
    "              'fs' : float(sampling_rate),\n",
    "              'diameter' : float(diameter), \n",
    "              'batch_size' : int(batch_size), \n",
    "              'nimg_init' : int(batch_size),\n",
    "              'nplanes' : n_planes[i] \n",
    "              })\n",
    "    \n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 tifs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\skimage\\external\\tifffile\\tifffile.py:1635: UserWarning: can not reshape (2000, 512, 512) to (30770, 512, 512)\n",
      "  warnings.warn(str(e))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30770\n",
      "time 1577.6624. Wrote tifs to binaries for 1 planes\n",
      "C:\\BIN\\suite2p\\plane0\\data_raw.bin\n",
      "computed reference frame for registration\n",
      "registered 2500/30770 frames in time 240.55\n",
      "registered 5000/30770 frames in time 478.96\n",
      "registered 7500/30770 frames in time 717.83\n",
      "registered 10000/30770 frames in time 957.22\n",
      "registered 12500/30770 frames in time 1195.59\n",
      "registered 15000/30770 frames in time 1433.72\n",
      "registered 17500/30770 frames in time 1673.76\n",
      "registered 20000/30770 frames in time 1911.99\n",
      "registered 22500/30770 frames in time 2150.23\n",
      "registered 25000/30770 frames in time 2388.64\n",
      "registered 27500/30770 frames in time 2623.74\n",
      "registered 30000/30770 frames in time 2860.98\n",
      "computed registration metrics in time 3048.85\n",
      "time 4861.7706. Registration complete for 1 planes\n",
      "[11 11]\n",
      "nt0=60\n",
      "(512, 504, 505)\n",
      "6.0\n",
      "ROIs: 108, cost: 0.0297, time: 199.2244\n",
      "ROIs: 160, cost: 0.0266, time: 219.3036\n",
      "ROIs: 170, cost: 0.0262, time: 225.3040\n",
      "nt0=60\n",
      "(512, 504, 505)\n",
      "ROIs: 170, cost: 0.1387, time: 255.0470\n",
      "removed 27 overlapping ROIs\n",
      "ROIs: 143, cost: 0.1166, time: 303.7427\n",
      "ROIs: 143, cost: 0.1139, time: 334.0993\n",
      "time 439.7212. Found 143 ROIs\n",
      "extracted 0/30770 frames in 1.37 sec\n",
      "extracted 5000/30770 frames in 8.78 sec\n",
      "extracted 10000/30770 frames in 16.21 sec\n",
      "extracted 15000/30770 frames in 23.28 sec\n",
      "extracted 20000/30770 frames in 30.61 sec\n",
      "extracted 25000/30770 frames in 37.80 sec\n",
      "extracted 30770/30770 frames in 44.93 sec\n",
      "time 492.9086. Extracted fluorescence from 143 ROIs\n",
      "results saved to P:rlees\\Data\\2019-03-12\\RL025\\2019-03-12_RL025_t-007\\MPTIFF\\suite2p\\plane0\n",
      "time 5406.9805. Detected spikes in 143 ROIs\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\suite2p\\classifiers/classifier_user.npy\n",
      "finished all tasks in total time 5423.5069 sec\n",
      "Found 1 tifs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\skimage\\external\\tifffile\\tifffile.py:1635: UserWarning: can not reshape (2000, 512, 512) to (2988, 512, 512)\n",
      "  warnings.warn(str(e))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2988\n",
      "time 145.2548. Wrote tifs to binaries for 1 planes\n",
      "C:\\BIN\\suite2p\\plane0\\data_raw.bin\n",
      "computed reference frame for registration\n",
      "registered 2500/2988 frames in time 233.74\n",
      "computed registration metrics in time 337.46\n",
      "time 658.8996. Registration complete for 1 planes\n",
      "[11 11]\n",
      "nt0=60\n",
      "(49, 507, 508)\n",
      "6.0\n",
      "ROIs: 200, cost: 0.1878, time: 9.7109\n",
      "ROIs: 400, cost: 0.1581, time: 15.7693\n",
      "ROIs: 553, cost: 0.1423, time: 20.3832\n",
      "ROIs: 579, cost: 0.1388, time: 23.3308\n",
      "ROIs: 585, cost: 0.1375, time: 25.7790\n",
      "nt0=60\n",
      "(49, 507, 508)\n",
      "ROIs: 585, cost: 0.2914, time: 29.1233\n",
      "removed 31 overlapping ROIs\n",
      "ROIs: 554, cost: 0.2657, time: 34.7572\n",
      "ROIs: 554, cost: 0.2645, time: 37.4006\n",
      "time 49.5184. Found 554 ROIs\n",
      "extracted 0/2988 frames in 2.02 sec\n",
      "extracted 2988/2988 frames in 6.53 sec\n",
      "time 64.8666. Extracted fluorescence from 554 ROIs\n",
      "results saved to P:aharris\\Data\\2019-04-11\\2019-04-11_RL025_t-006\\suite2p\\plane0\n",
      "time 764.9155. Detected spikes in 554 ROIs\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\suite2p\\classifiers/classifier_user.npy\n",
      "finished all tasks in total time 780.8562 sec\n",
      "Found 1 tifs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\skimage\\external\\tifffile\\tifffile.py:1635: UserWarning: can not reshape (2000, 512, 512) to (30472, 512, 512)\n",
      "  warnings.warn(str(e))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30472\n",
      "time 1517.1066. Wrote tifs to binaries for 1 planes\n",
      "C:\\BIN\\suite2p\\plane0\\data_raw.bin\n",
      "computed reference frame for registration\n",
      "registered 2500/30472 frames in time 244.77\n",
      "registered 5000/30472 frames in time 488.98\n",
      "registered 7500/30472 frames in time 734.23\n",
      "registered 10000/30472 frames in time 979.23\n",
      "registered 12500/30472 frames in time 1217.37\n",
      "registered 15000/30472 frames in time 1456.54\n",
      "registered 17500/30472 frames in time 1695.16\n",
      "registered 20000/30472 frames in time 1935.21\n",
      "registered 22500/30472 frames in time 2174.63\n",
      "registered 25000/30472 frames in time 2414.67\n",
      "registered 27500/30472 frames in time 2653.29\n",
      "registered 30000/30472 frames in time 2900.43\n",
      "computed registration metrics in time 3085.57\n",
      "time 4841.5600. Registration complete for 1 planes\n",
      "[11 11]\n",
      "nt0=60\n",
      "(507, 505, 506)\n",
      "6.0\n",
      "ROIs: 200, cost: 0.1314, time: 53.7915\n",
      "ROIs: 400, cost: 0.1061, time: 61.7396\n",
      "ROIs: 491, cost: 0.0995, time: 67.0337\n",
      "ROIs: 502, cost: 0.0984, time: 71.1602\n",
      "nt0=60\n",
      "(507, 505, 506)\n",
      "ROIs: 502, cost: 0.2466, time: 99.4589\n",
      "removed 32 overlapping ROIs\n",
      "ROIs: 470, cost: 0.2325, time: 105.9593\n",
      "ROIs: 470, cost: 0.2311, time: 109.3155\n",
      "time 120.0187. Found 470 ROIs\n",
      "extracted 0/30472 frames in 2.04 sec\n",
      "extracted 5000/30472 frames in 12.81 sec\n",
      "extracted 10000/30472 frames in 23.77 sec\n",
      "extracted 15000/30472 frames in 34.17 sec\n",
      "extracted 20000/30472 frames in 45.07 sec\n",
      "extracted 25000/30472 frames in 55.84 sec\n",
      "extracted 30472/30472 frames in 65.74 sec\n",
      "time 192.7559. Extracted fluorescence from 470 ROIs\n",
      "results saved to P:aharris\\Data\\2019-04-11\\2019-04-11_RL025_t-007\\suite2p\\plane0\n",
      "time 5115.0542. Detected spikes in 470 ROIs\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\suite2p\\classifiers/classifier_user.npy\n",
      "finished all tasks in total time 5133.5459 sec\n",
      "Found 1 tifs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\skimage\\external\\tifffile\\tifffile.py:1635: UserWarning: can not reshape (2000, 512, 512) to (3287, 512, 512)\n",
      "  warnings.warn(str(e))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3287\n",
      "time 166.9700. Wrote tifs to binaries for 1 planes\n",
      "C:\\BIN\\suite2p\\plane0\\data_raw.bin\n",
      "computed reference frame for registration\n",
      "registered 2500/3287 frames in time 244.31\n",
      "computed registration metrics in time 387.25\n",
      "time 737.8819. Registration complete for 1 planes\n",
      "[11 11]\n",
      "nt0=60\n",
      "(54, 509, 509)\n",
      "6.0\n",
      "ROIs: 200, cost: 0.1372, time: 18.2481\n",
      "ROIs: 400, cost: 0.0982, time: 24.9589\n",
      "ROIs: 504, cost: 0.0899, time: 29.2192\n",
      "ROIs: 525, cost: 0.0876, time: 31.9559\n",
      "ROIs: 531, cost: 0.0867, time: 34.5032\n",
      "nt0=60\n",
      "(54, 509, 509)\n",
      "ROIs: 531, cost: 0.2238, time: 38.4076\n",
      "removed 45 overlapping ROIs\n",
      "ROIs: 486, cost: 0.2153, time: 44.6417\n",
      "ROIs: 486, cost: 0.2127, time: 48.7879\n",
      "time 61.3040. Found 486 ROIs\n",
      "extracted 0/3287 frames in 2.00 sec\n",
      "extracted 3287/3287 frames in 7.42 sec\n",
      "time 77.3891. Extracted fluorescence from 486 ROIs\n",
      "results saved to P:aharris\\Data\\2019-04-11\\2019-04-11_RL025_t-008\\suite2p\\plane0\n",
      "time 856.9694. Detected spikes in 486 ROIs\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\suite2p\\classifiers/classifier_user.npy\n",
      "finished all tasks in total time 871.7947 sec\n",
      "Found 1 tifs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\skimage\\external\\tifffile\\tifffile.py:1635: UserWarning: can not reshape (2000, 512, 512) to (30472, 512, 512)\n",
      "  warnings.warn(str(e))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30472\n",
      "time 1478.5729. Wrote tifs to binaries for 1 planes\n",
      "C:\\BIN\\suite2p\\plane0\\data_raw.bin\n",
      "computed reference frame for registration\n",
      "registered 2500/30472 frames in time 248.85\n",
      "registered 5000/30472 frames in time 498.59\n",
      "registered 7500/30472 frames in time 746.57\n",
      "registered 10000/30472 frames in time 995.64\n",
      "registered 12500/30472 frames in time 1243.85\n",
      "registered 15000/30472 frames in time 1491.65\n",
      "registered 17500/30472 frames in time 1738.51\n",
      "registered 20000/30472 frames in time 1984.35\n",
      "registered 22500/30472 frames in time 2217.67\n",
      "registered 25000/30472 frames in time 2451.10\n",
      "registered 27500/30472 frames in time 2685.01\n",
      "registered 30000/30472 frames in time 2917.83\n",
      "computed registration metrics in time 3083.22\n",
      "time 4797.1679. Registration complete for 1 planes\n",
      "[11 11]\n",
      "nt0=60\n",
      "(507, 507, 508)\n",
      "6.0\n",
      "ROIs: 200, cost: 0.2817, time: 49.7698\n",
      "ROIs: 400, cost: 0.2349, time: 59.2596\n",
      "ROIs: 507, cost: 0.2205, time: 65.2806\n",
      "ROIs: 538, cost: 0.2169, time: 69.4039\n",
      "ROIs: 545, cost: 0.2158, time: 73.1800\n",
      "nt0=60\n",
      "(507, 507, 508)\n",
      "ROIs: 545, cost: 0.4053, time: 100.1811\n",
      "removed 36 overlapping ROIs\n",
      "ROIs: 509, cost: 0.3619, time: 108.0214\n",
      "ROIs: 509, cost: 0.3586, time: 111.5399\n",
      "time 124.2930. Found 509 ROIs\n",
      "extracted 0/30472 frames in 2.01 sec\n",
      "extracted 5000/30472 frames in 12.56 sec\n",
      "extracted 10000/30472 frames in 23.02 sec\n",
      "extracted 15000/30472 frames in 33.89 sec\n",
      "extracted 20000/30472 frames in 44.62 sec\n",
      "extracted 25000/30472 frames in 54.96 sec\n",
      "extracted 30472/30472 frames in 65.16 sec\n",
      "time 197.9752. Extracted fluorescence from 509 ROIs\n",
      "results saved to P:aharris\\Data\\2019-04-11\\2019-04-11_RL025_t-009\\suite2p\\plane0\n",
      "time 5075.3076. Detected spikes in 509 ROIs\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\suite2p\\classifiers/classifier_user.npy\n",
      "finished all tasks in total time 5092.4392 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17302.224670171738"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "for dbi in db:\n",
    "    opsEnd = run_s2p(ops=ops,db=dbi)\n",
    "    \n",
    "t2 = time.time()\n",
    "t2 - t1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
