{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#ipython magic\n",
    "%reset -f\n",
    "%matplotlib notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general imports\n",
    "import sys\n",
    "sys.path.append(r'C:\\Users\\Robert Lees\\Documents\\Code\\Vape\\suite2p_etc')\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\suite2p']\n"
     ]
    }
   ],
   "source": [
    "#notebook specific imports\n",
    "from utils.gsheets_importer import gsheet2df, correct_behaviour_df, split_df, df_bool, df_col, path_conversion\n",
    "from utils.artifact_removal import artifact_removal\n",
    "from utils.utils_funcs import *\n",
    "from utils.paq2py import *\n",
    "import tifffile\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import suite2p\n",
    "print(suite2p.__path__)\n",
    "from suite2p.run_s2p import run_s2p\n",
    "from settings import ops\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P:rlees\\\\Data\\\\2019-05-03\\\\RL035\\\\2019-05-03_RL035_t-002\\\\MPTIFF',\n",
       " 'P:rlees\\\\Data\\\\2019-05-09\\\\RL035\\\\2019-05-09_RL035_t-002']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read g sheets to populate some lists for processing stim artifact and running suite2p\n",
    "\n",
    "sheet_ID = '1Z9CvuA1qlLsB0Gar48bkZscLhtlP9iIWk4PYZur8cvc'\n",
    "SHEET_NAME = '2019-05-23_artifact_removal_s2p'\n",
    "df = gsheet2df(sheet_ID, HEADER_ROW=4, SHEET_NAME=SHEET_NAME)\n",
    "\n",
    "# at this point we have lots of files that could be whisker stim or photostim, need to find out which is which\n",
    "\n",
    "for_processing = split_df(df, 's2p_me') # only files with TRUE in suite2p_me column\n",
    "\n",
    "if not for_processing.shape[0]:\n",
    "    raise Exception('ERROR: no files set for processing')\n",
    "\n",
    "stim = for_processing.loc[:,'stim'] # find out what stims have been carried out\n",
    "photostim_idx = [i for i,stim in enumerate(stim) if stim=='p'] # row indices of all photostim exps (for artifact removal)\n",
    "whisker_stim_idx = [i for i,stim in enumerate(stim) if stim=='w2p'] # '' for whisker stim (no artifact removal)\n",
    "\n",
    "tiff_paths = for_processing.loc[:,'tiff_path']\n",
    "paq_paths = for_processing.loc[:,'paq_path']\n",
    "\n",
    "if not all(tiff_paths) or not all(paq_paths):\n",
    "    raise Exception('ERROR: missing tiff or paq paths')\n",
    "    \n",
    "# below is information that will be later required for suite2p and stim removal\n",
    "\n",
    "n_frames = [int(i) for i in list(for_processing.loc[:,'n_frames'])] # for stim removal\n",
    "stim_dur = [int(i) for i in list(for_processing.loc[:,'total_stim_duration'])] # for stim removal\n",
    "n_planes = [int(i) for i in list(for_processing.loc[:,'n_planes'])] # for s2p and stim removal\n",
    "\n",
    "if not all(n_frames) or not all(stim_dur) or not all(n_planes):\n",
    "    raise Exception('ERROR: missing important metadata for processing')\n",
    "\n",
    "packerstation_path = r\"P:\" # the path to PackerStation on the local machine\n",
    "\n",
    "tiffs_pstation = path_conversion(tiff_paths, packerstation_path) # convert paths (from Packer1 or PackerStation) to local PackerStation paths\n",
    "paqs_pstation = path_conversion(paq_paths, packerstation_path)\n",
    "\n",
    "tiffs_pstation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(512, 512), (512, 512)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use first frame of tiffs to find resolution of image, required later for calculating cell diameter in pixels for s2p\n",
    "\n",
    "frame_size = [] \n",
    "\n",
    "for tiff_path in tiffs_pstation:\n",
    "    frame = []\n",
    "    if '.tif' in tiff_path or '.tiff' in tiff_path: # the path points directly to a file\n",
    "        frame = tifffile.imread(tiff_path, key=0) \n",
    "        frame_size.append(frame.shape)\n",
    "        break\n",
    "    else:\n",
    "        for item in os.listdir(tiff_path): # the path points to a folder\n",
    "            if '.tif' in item or '.tiff' in item:\n",
    "                filename = os.path.join(tiff_path, item)\n",
    "                frame = tifffile.imread(filename, key=0)\n",
    "                frame_size.append(frame.shape)\n",
    "                break\n",
    "        if frame == []: \n",
    "            print(tiff_path)\n",
    "            raise Exception('ERROR: could not load a TIFF file')\n",
    "\n",
    "frame_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:rlees\\Data\\2019-05-03\\RL035\\2019-05-03_RL035_t-002\\MPTIFF\n",
      "P:rlees\\Data\\2019-05-09\\RL035\\2019-05-09_RL035_t-002\n"
     ]
    }
   ],
   "source": [
    "# obtain list of tiffs to run stim removal on\n",
    "\n",
    "tiff_lists = []\n",
    "\n",
    "# need to find single multi-page TIFF or many TIFFs/MPTIFFs\n",
    "\n",
    "for tiff in tiffs_pstation:\n",
    "    print(tiff)\n",
    "    if '.tif' not in tiff or '.tiff' not in tiff: # if the provided path is not directly a TIFF, it may be folder with MPTIFF or multiple TIFFs/MPTIFFs\n",
    "        items = os.listdir(tiff)\n",
    "        newlist = []\n",
    "        \n",
    "        for name in items:\n",
    "            if name.endswith(\".tiff\") or name.endswith(\".tif\"):\n",
    "                filename = os.path.join(tiff, name)\n",
    "                newlist.append(filename)\n",
    "        tiff_lists.append(newlist)\n",
    "        \n",
    "    else:\n",
    "        tiff_lists.append(tiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([  85,   86,   87,   88,   89,   90,   91,   92,   93,   94,  384,\n",
       "         385,  386,  387,  388,  389,  390,  391,  392,  393,  682,  683,\n",
       "         684,  685,  686,  687,  688,  689,  690,  691,  981,  982,  983,\n",
       "         984,  985,  986,  987,  988,  989,  990, 1280, 1281, 1282, 1283,\n",
       "        1284, 1285, 1286, 1287, 1288, 1289, 1579, 1580, 1581, 1582, 1583,\n",
       "        1584, 1585, 1586, 1587, 1588, 1877, 1878, 1879, 1880, 1881, 1882,\n",
       "        1883, 1884, 1885, 1886, 2176, 2177, 2178, 2179, 2180, 2181, 2182,\n",
       "        2183, 2184, 2185, 2475, 2476, 2477, 2478, 2479, 2480, 2481, 2482,\n",
       "        2483, 2484, 2774, 2775, 2776, 2777, 2778, 2779, 2780, 2781, 2782,\n",
       "        2783], dtype=int64),\n",
       " array([  74,   75,   76,   77,   78,   79,   80,   81,   82,   83,   84,\n",
       "          85,   86,   87,   88,   89,   90,   91,   92,   93,   94,   95,\n",
       "          96,   97,   98,   99,  100,  101,  102,  103,  104,  105,  106,\n",
       "         107,  108,  109,  110,  111,  112,  113,  114,  115,  116,  117,\n",
       "         118,  119,  120,  373,  374,  375,  376,  377,  378,  379,  380,\n",
       "         381,  382,  383,  384,  385,  386,  387,  388,  389,  390,  391,\n",
       "         392,  393,  394,  395,  396,  397,  398,  399,  400,  401,  402,\n",
       "         403,  404,  405,  406,  407,  408,  409,  410,  411,  412,  413,\n",
       "         414,  415,  416,  417,  418,  419,  672,  673,  674,  675,  676,\n",
       "         677,  678,  679,  680,  681,  682,  683,  684,  685,  686,  687,\n",
       "         688,  689,  690,  691,  692,  693,  694,  695,  696,  697,  698,\n",
       "         699,  700,  701,  702,  703,  704,  705,  706,  707,  708,  709,\n",
       "         710,  711,  712,  713,  714,  715,  716,  717,  718,  970,  971,\n",
       "         972,  973,  974,  975,  976,  977,  978,  979,  980,  981,  982,\n",
       "         983,  984,  985,  986,  987,  988,  989,  990,  991,  992,  993,\n",
       "         994,  995,  996,  997,  998,  999, 1000, 1001, 1002, 1003, 1004,\n",
       "        1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015,\n",
       "        1016, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278,\n",
       "        1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289,\n",
       "        1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300,\n",
       "        1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311,\n",
       "        1312, 1313, 1314, 1315, 1568, 1569, 1570, 1571, 1572, 1573, 1574,\n",
       "        1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585,\n",
       "        1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596,\n",
       "        1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607,\n",
       "        1608, 1609, 1610, 1611, 1612, 1613, 1614, 1867, 1868, 1869, 1870,\n",
       "        1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1879, 1880, 1881,\n",
       "        1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892,\n",
       "        1893, 1894, 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1902, 1903,\n",
       "        1904, 1905, 1906, 1907, 1908, 1909, 1910, 1911, 1912, 1913, 2165,\n",
       "        2166, 2167, 2168, 2169, 2170, 2171, 2172, 2173, 2174, 2175, 2176,\n",
       "        2177, 2178, 2179, 2180, 2181, 2182, 2183, 2184, 2185, 2186, 2187,\n",
       "        2188, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2196, 2197, 2198,\n",
       "        2199, 2200, 2201, 2202, 2203, 2204, 2205, 2206, 2207, 2208, 2209,\n",
       "        2210, 2211, 2464, 2465, 2466, 2467, 2468, 2469, 2470, 2471, 2472,\n",
       "        2473, 2474, 2475, 2476, 2477, 2478, 2479, 2480, 2481, 2482, 2483,\n",
       "        2484, 2485, 2486, 2487, 2488, 2489, 2490, 2491, 2492, 2493, 2494,\n",
       "        2495, 2496, 2497, 2498, 2499, 2500, 2501, 2502, 2503, 2504, 2505,\n",
       "        2506, 2507, 2508, 2509, 2510, 2763, 2764, 2765, 2766, 2767, 2768,\n",
       "        2769, 2770, 2771, 2772, 2773, 2774, 2775, 2776, 2777, 2778, 2779,\n",
       "        2780, 2781, 2782, 2783, 2784, 2785, 2786, 2787, 2788, 2789, 2790,\n",
       "        2791, 2792, 2793, 2794, 2795, 2796, 2797, 2798, 2799, 2800, 2801,\n",
       "        2802, 2803, 2804, 2805, 2806, 2807, 2808, 2809], dtype=int64)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load up paq file and find stim times + start frames\n",
    "\n",
    "remove_frames = []\n",
    "\n",
    "for i,_ in enumerate(tiff_lists):\n",
    "    paq = paq_read(paqs_pstation[i])\n",
    "    stim_frames = stim_start_frame(paq, 'markpoints2packio')\n",
    "    frame_clock = paq_data(paq, 'frame_clock', threshold_ttl=True)\n",
    "\n",
    "    duration_ms = stim_dur[i] #length of stim\n",
    "    duration_samples = (int(duration_ms) / 1000) * paq['rate']\n",
    "    \n",
    "    # use this to remove frames during stim based on paq\n",
    "    to_remove = []\n",
    "\n",
    "    for stim_frame in stim_frames: \n",
    "\n",
    "        # frame indexes that fall during the stim\n",
    "        in_stim = np.where((frame_clock >= stim_frame) & (frame_clock <= stim_frame + duration_samples))[0]\n",
    "\n",
    "        #empircal observation, these are the frames with artifact\n",
    "        in_stim = np.append(in_stim, in_stim[-1]+1)\n",
    "        in_stim = np.append(in_stim, in_stim[-1]+1)\n",
    "\n",
    "        to_remove.append(in_stim)\n",
    "\n",
    "    remove_frames.append(np.ravel(to_remove))\n",
    "\n",
    "remove_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:rlees\\Data\\2019-05-03\\RL035\\2019-05-03_RL035_t-002\\MPTIFF\\Artifact_removed\n",
      "2019-05-03_RL035_t-002_Cycle00658_Ch3\n",
      "Multiple TIFF files\n",
      "P:rlees\\Data\\2019-05-09\\RL035\\2019-05-09_RL035_t-002\\Artifact_removed\n",
      "2019-05-09_RL035_t-002_Cycle00001_Ch3\n",
      "Single TIFF file\n"
     ]
    }
   ],
   "source": [
    "# load up TIFFs in blocks and run stim removal on them\n",
    "user_block_size = 500 # should be above 100 to work without problems\n",
    "\n",
    "for i,tiff_list in enumerate(tiff_lists): # for each list of TIFFs\n",
    "\n",
    "    parent_dir = os.path.dirname(tiff_list[0]) # parent directory to create output directory inside of\n",
    "    output_dir = os.path.join(parent_dir, 'Artifact_removed')\n",
    "    print(output_dir)\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(output_dir) # make output directory for artifact removal TIFFs\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    base_path = os.path.splitext(tiff_list[0])[0] # get parent folder of TIFF for saving files\n",
    "    base_filename = os.path.basename(base_path)\n",
    "    print(base_filename)\n",
    "    \n",
    "    substack = np.empty((0,512,512), dtype=np.uint16) # empty np array for appending to\n",
    "    \n",
    "    block_size = myround(user_block_size, base=n_planes[i]) # want the block_size to be in multiples of the number of planes if multiplanar TIFF\n",
    "    \n",
    "    iteration = 0\n",
    "    prev_frames = 0\n",
    "    current_frames = 0\n",
    "    \n",
    "    width_thresh = 5 * (frame_size[i][0] / 512) # currently using 5 pixels as default for 512 image, scaled for other resolution\n",
    "    \n",
    "    if len(tiff_list)>1: # multiple TIFFs or MPTIFFs\n",
    "        print('Multiple TIFF files')\n",
    "        tiff_list = sorted(tiff_list) \n",
    "        \n",
    "        for tiff in tiff_list:\n",
    "            \n",
    "            temp_tiff = tifffile.imread(tiff)\n",
    "            substack = np.append(substack, temp_tiff, axis=0)\n",
    "            \n",
    "            if substack.shape[0]>block_size or tiff==tiff_list[-1]: # if substack is large (RAM conservation) or at last TIFF in list, process the stack\n",
    "                \n",
    "                substack_frames = substack.shape[0] # number of frames in current stack\n",
    "                current_frames = substack_frames + prev_frames\n",
    "                remove_me = [frame - prev_frames for frame in remove_frames[i] if prev_frames <= frame < current_frames] # slice the frames to be removed for this substack\n",
    "                \n",
    "                non_stim_frames = [non_stim for non_stim,_ in enumerate(substack) if non_stim not in remove_me]\n",
    "                thresh_list = non_stim_frames[:50]\n",
    "                \n",
    "                if remove_me:\n",
    "                    substack_processed = artifact_removal(substack, thresh_list=thresh_list, remove_me=remove_me, width_thresh=width_thresh, nplanes=n_planes[i]) # remove artifact\n",
    "                else:\n",
    "                    substack_processed = substack\n",
    "                \n",
    "                filename = base_filename + '_artifactRemoved' + str(iteration) + '.tiff'\n",
    "                output_path = os.path.join(output_dir, filename)\n",
    "                tifffile.imwrite(output_path, substack_processed) # write processed tiff\n",
    "                \n",
    "                substack = np.empty((0,512,512), dtype=np.uint16)\n",
    "                iteration += 1\n",
    "                prev_frames = current_frames # save which frame we are at (for calculating stims to include next time)\n",
    "                    \n",
    "    else: # single, large MPTIFF\n",
    "        print('Single TIFF file')\n",
    "        remaining_frames = n_frames[i]\n",
    "        \n",
    "        while remaining_frames:\n",
    "            \n",
    "            if remaining_frames > block_size: # load a block of TIFF pages unless there are fewer than a block left, should pre-define block according to RAM capacity\n",
    "                current_frames += block_size\n",
    "            else:\n",
    "                current_frames += remaining_frames # load all remaining TIFF pages\n",
    "            \n",
    "            substack = tifffile.imread(tiff_list, key=range(prev_frames, current_frames)) # load in all frames for this block starting from the previous block\n",
    "            \n",
    "            remove_me = [frame - prev_frames for frame in remove_frames[i] if prev_frames <= frame < current_frames] # slice the frames to be removed so they are for this substack only\n",
    "            \n",
    "            non_stim_frames = [non_stim for non_stim,_ in enumerate(substack) if non_stim not in remove_me] # sometimes can't find threshold so find non-stim frames and provide it to artifact removal\n",
    "            thresh_list = non_stim_frames[:50] # list of frames for threshold in artifact removal function\n",
    "            \n",
    "            if remove_me:\n",
    "                substack_processed = artifact_removal(substack, thresh_list=thresh_list, remove_me=remove_me, width_thresh=width_thresh, nplanes=n_planes[i]) # remove artifact\n",
    "            else:\n",
    "                substack_processed = substack # if no frames to be removed\n",
    "                    \n",
    "            filename = base_filename + '_artifactRemoved' + str(iteration) + '.tiff' # construct filename\n",
    "            output_path = os.path.join(output_dir, filename)\n",
    "            tifffile.imwrite(output_path, substack_processed) # write processed tiff\n",
    "            iteration += 1 \n",
    "            prev_frames = current_frames # save progress in terms of frames with artifact removed\n",
    "                        \n",
    "            remaining_frames = n_frames[i] - current_frames # frames remaining to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling rate\n",
    "fps = for_processing.loc[:,'fps'] \n",
    "sampling_rate = fps/n_planes\n",
    "print(sampling_rate)\n",
    "\n",
    "# cell diameter\n",
    "zoom = for_processing.loc[:,'zoom'] # for s2p cell diameter calculation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
