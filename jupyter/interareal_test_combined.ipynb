{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipython magic\n",
    "\n",
    "# %reset -f\n",
    "# %matplotlib notebook\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\suite2p']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append(r'C:\\Users\\Robert Lees\\Documents\\Code\\Vape\\rob_suite2p')\n",
    "# sys.path.append(r'C:\\Users\\Robert Lees\\Documents\\Code\\suite2p')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import utils.interareal_combined_class as iac\n",
    "import pickle\n",
    "import tifffile as tf\n",
    "from scipy import spatial, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching paths and stim types for: 2019-06-25_RL048\n",
      "Umbrella folder: P:\\sarmstrong\\Data\\2019-06-25\n",
      "Experimental info = (array(['P:\\\\sarmstrong\\\\Data\\\\2019-06-25\\\\RL048\\\\2019-06-24_RL048_t-005',\n",
      "       'P:\\\\sarmstrong\\\\Data\\\\2019-06-25\\\\RL048\\\\2019-06-24_RL048_NAPARM\\\\2019-06-25_RL048_NAPARM_003',\n",
      "       'P:\\\\sarmstrong\\\\Data\\\\2019-06-25\\\\RL048\\\\2019-06-25_RL048_t-005.paq'],\n",
      "      dtype='<U87'), array(['P:\\\\sarmstrong\\\\Data\\\\2019-06-25\\\\RL048\\\\2019-06-24_RL048_t-006\\\\MPTIFF',\n",
      "       'P:\\\\sarmstrong\\\\Data\\\\2019-06-25\\\\RL048\\\\2019-06-24_RL048_NAPARM\\\\2019-06-25_RL048_NAPARM_004',\n",
      "       'P:\\\\sarmstrong\\\\Data\\\\2019-06-25\\\\RL048\\\\2019-06-25_RL048_t-006.paq'],\n",
      "      dtype='<U87'), array([], dtype='<U87'), array([], dtype='<U87'))\n",
      "\n",
      "Obtaining metadata for: P:\\sarmstrong\\Data\\2019-06-25\\RL048\\2019-06-24_RL048_t-005\n",
      "n_planes: 1 \n",
      "n_frames: 46128 \n",
      "fps: 29.759711754574276 \n",
      "frame size: 964 x 514 \n",
      "zoom: 0.8316588768 \n",
      "pixel size: 1.31338993281181 1.31338993281181 \n",
      "scan_um: 0.03677781721508 -0.5268204275444\n",
      "\n",
      "NAPARM xml: P:\\sarmstrong\\Data\\2019-06-25\\RL048\\2019-06-24_RL048_NAPARM\\2019-06-25_RL048_NAPARM_003\\2019-06-25_RL048_NAPARM_003.xml\n",
      "Numbers of trials: 100 \n",
      "Inter-group delay: 5 \n",
      "Number of groups: 4 \n",
      "Number of shots: 1 \n",
      "Number of sequence reps: 10\n",
      "\n",
      "NAPARM gpl: P:\\sarmstrong\\Data\\2019-06-25\\RL048\\2019-06-24_RL048_NAPARM\\2019-06-25_RL048_NAPARM_003\\2019-06-25_RL048_NAPARM_003.gpl\n",
      "single stim duration (ms): 10.0 \n",
      "spiral size (um): 10\n",
      "\n",
      "Finding stim frames from: P:\\sarmstrong\\Data\\2019-06-25\\RL048\\2019-06-25_RL048_t-005.paq\n",
      "total stim duration (frames): 18\n",
      "\n",
      "Obtaining metadata for: P:\\sarmstrong\\Data\\2019-06-25\\RL048\\2019-06-24_RL048_t-006\\MPTIFF\n",
      "n_planes: 1 \n",
      "n_frames: 46128 \n",
      "fps: 29.759711754574276 \n",
      "frame size: 964 x 514 \n",
      "zoom: 0.8316588768 \n",
      "pixel size: 1.31338993281181 1.31338993281181 \n",
      "scan_um: 0.03677781721508 -0.5268204275444\n",
      "\n",
      "NAPARM xml: P:\\sarmstrong\\Data\\2019-06-25\\RL048\\2019-06-24_RL048_NAPARM\\2019-06-25_RL048_NAPARM_004\\2019-06-25_RL048_NAPARM_004.xml\n",
      "Numbers of trials: 100 \n",
      "Inter-group delay: 5 \n",
      "Number of groups: 2 \n",
      "Number of shots: 1 \n",
      "Number of sequence reps: 10\n",
      "\n",
      "NAPARM gpl: P:\\sarmstrong\\Data\\2019-06-25\\RL048\\2019-06-24_RL048_NAPARM\\2019-06-25_RL048_NAPARM_004\\2019-06-25_RL048_NAPARM_004.gpl\n",
      "single stim duration (ms): 10.0 \n",
      "spiral size (um): 10\n",
      "\n",
      "Finding stim frames from: P:\\sarmstrong\\Data\\2019-06-25\\RL048\\2019-06-25_RL048_t-006.paq\n",
      "total stim duration (frames): 9\n",
      "\n",
      "No metadata for this w stim experiment\n",
      "\n",
      "No metadata for this none stim experiment\n",
      "\n",
      "Calculating frame ranges...\n",
      "\n",
      "s2p ops: {'data_path': ['P:\\\\sarmstrong\\\\Data\\\\2019-06-25\\\\RL048\\\\2019-06-24_RL048_t-005', 'P:\\\\sarmstrong\\\\Data\\\\2019-06-25\\\\RL048\\\\2019-06-24_RL048_t-006\\\\MPTIFF'], 'fs': 29.759711754574276, 'diameter': (9, 9), 'nplanes': 1}\n",
      "{'data_path': ['P:\\\\sarmstrong\\\\Data\\\\2019-06-25\\\\RL048\\\\2019-06-24_RL048_t-005', 'P:\\\\sarmstrong\\\\Data\\\\2019-06-25\\\\RL048\\\\2019-06-24_RL048_t-006\\\\MPTIFF'], 'fs': 29.759711754574276, 'diameter': (9, 9), 'nplanes': 1}\n",
      "** Found 2 tifs - converting to binary **\n",
      "4000 frames of binary, time 604.13 sec.\n",
      "8000 frames of binary, time 669.13 sec.\n",
      "12000 frames of binary, time 734.25 sec.\n",
      "16000 frames of binary, time 800.90 sec.\n",
      "20000 frames of binary, time 867.05 sec.\n",
      "24000 frames of binary, time 931.77 sec.\n",
      "28000 frames of binary, time 999.09 sec.\n",
      "32000 frames of binary, time 1063.81 sec.\n",
      "36000 frames of binary, time 1129.65 sec.\n",
      "40000 frames of binary, time 1198.12 sec.\n",
      "44000 frames of binary, time 1262.97 sec.\n",
      "time 2077.71 sec. Wrote tifs to binaries for 1 planes\n",
      ">>>>>>>>>>>>>>>>>>>>> PLANE 0 <<<<<<<<<<<<<<<<<<<<<<\n",
      "----------- REGISTRATION\n",
      "registering 92256 frames\n",
      "Reference frame, 44.60 sec.\n",
      "5000/92256 frames, 181.79 sec.\n",
      "10000/92256 frames, 367.52 sec.\n",
      "15000/92256 frames, 527.11 sec.\n",
      "20000/92256 frames, 689.33 sec.\n",
      "25000/92256 frames, 851.91 sec.\n",
      "30000/92256 frames, 1013.27 sec.\n",
      "35000/92256 frames, 1193.69 sec.\n",
      "40000/92256 frames, 1351.32 sec.\n",
      "45000/92256 frames, 1531.85 sec.\n",
      "50000/92256 frames, 1689.07 sec.\n",
      "55000/92256 frames, 1848.27 sec.\n",
      "60000/92256 frames, 2009.00 sec.\n",
      "65000/92256 frames, 2171.13 sec.\n",
      "70000/92256 frames, 2360.50 sec.\n",
      "75000/92256 frames, 2522.74 sec.\n",
      "80000/92256 frames, 2675.03 sec.\n",
      "85000/92256 frames, 2855.43 sec.\n",
      "90000/92256 frames, 3034.52 sec.\n",
      "92256/92256 frames, 3107.18 sec.\n",
      "200\n",
      "----------- Total 3153.26 sec\n",
      "Registration metrics, 58.67 sec.\n",
      "----------- ROI DETECTION AND EXTRACTION\n",
      "Binning movie in chunks of length 37\n",
      "Binned movie [2307,510,959], 550.28 sec.\n",
      "ROIs: 200, cost: 0.2714, time: 609.5009\n",
      "ROIs: 400, cost: 0.2450, time: 631.7684\n",
      "ROIs: 600, cost: 0.2290, time: 656.4032\n",
      "ROIs: 800, cost: 0.2180, time: 682.6798\n",
      "ROIs: 1000, cost: 0.2101, time: 709.1076\n",
      "ROIs: 1200, cost: 0.2036, time: 737.6361\n",
      "ROIs: 1400, cost: 0.1984, time: 767.6026\n",
      "ROIs: 1600, cost: 0.1941, time: 799.0544\n",
      "ROIs: 1800, cost: 0.1903, time: 832.4859\n",
      "ROIs: 2000, cost: 0.1868, time: 867.1784\n",
      "ROIs: 2200, cost: 0.1839, time: 904.2586\n",
      "ROIs: 2400, cost: 0.1814, time: 944.5529\n",
      "ROIs: 2542, cost: 0.1796, time: 985.7236\n",
      "ROIs: 2623, cost: 0.1786, time: 1027.7348\n",
      "ROIs: 2672, cost: 0.1779, time: 1069.5915\n",
      "ROIs: 2711, cost: 0.1774, time: 1112.7223\n",
      "ROIs: 2744, cost: 0.1769, time: 1154.7228\n",
      "ROIs: 2769, cost: 0.1766, time: 1196.9041\n",
      "ROIs: 2788, cost: 0.1764, time: 1238.9360\n",
      "Binning movie in chunks of length 37\n",
      "Binned movie [2307,510,959], 550.76 sec.\n",
      "ROIs: 2788, cost: 0.4661, time: 1815.1923\n",
      "ROIs: 2788, cost: 0.4425, time: 1840.3495\n",
      "ROIs: 2788, cost: 0.4416, time: 1863.4007\n",
      "Found 2788 ROIs, 1892.46 sec\n",
      "NOTE: applying classifier C:\\ProgramData\\Anaconda3\\lib\\site-packages\\suite2p\\classifiers/classifier_user.npy\n",
      "After removing overlaps, 2788 ROIs remain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masks made in 69.47 sec.\n",
      "Extracted fluorescence from 2788 ROIs in 92256 frames, 1191.55 sec.\n",
      "----------- Total 3189.67 sec.\n",
      "----------- SPIKE DECONVOLUTION\n",
      "----------- Total 452.97 sec.\n",
      "Plane 0 processed in 6857.61 sec (can open in GUI).\n",
      "total = 3704.35 sec.\n",
      "TOTAL RUNTIME 3711.61 sec\n"
     ]
    }
   ],
   "source": [
    "ss_id = '1PgSXs6BVHe9dACWEydykucN74rirNfOY4Vr_AmLcCdY'\n",
    "sheet_names = ['2019-06-25_RL048']\n",
    "pstation_path = r'P:\\sarmstrong\\Data'\n",
    "pkl_folder = r'P:\\rlees\\pkl_files'\n",
    "\n",
    "for sheet_name in sheet_names:\n",
    "    exp_obj = iac.experimentInfo(ss_id, sheet_name, pstation_path)\n",
    "    \n",
    "    pkl_path = os.path.join(pkl_folder, sheet_name + '.pkl')\n",
    "\n",
    "    exp_obj.s2pRun()\n",
    "    \n",
    "    with open(pkl_path, 'wb') as f:\n",
    "        pickle.dump(exp_obj, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_border = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get some basic summary stats from the datasets - UPDATE THIS, IT WONT WORK WITH COMBINED OBJECT\n",
    "\n",
    "pkl_folder = r'P:\\rlees\\pkl_files'\n",
    "\n",
    "n_units = []\n",
    "n_targets = []\n",
    "n_targeted_cells = []\n",
    "stim_dur = []\n",
    "stim_freq = []\n",
    "\n",
    "for root, dirs, files in os.walk(pkl_folder):\n",
    "    for file in files:\n",
    "        pkl_path = os.path.join(pkl_folder, file)\n",
    "        \n",
    "        if any(s in pkl_path for s in ['random', 'sensory']):\n",
    "            with open(pkl_path, 'rb') as f:\n",
    "                exp_obj = pickle.load(f)\n",
    "\n",
    "            print(exp_obj.tiff_path)\n",
    "\n",
    "            print(exp_obj.n_units, exp_obj.n_targets)\n",
    "            n_units.append(exp_obj.n_units[0])\n",
    "            n_targets.append(exp_obj.n_targets)\n",
    "            n_targeted_cells.append(len([i for i in exp_obj.targeted_cells if i==1]))\n",
    "            stim_dur.append(exp_obj.stim_dur)\n",
    "            stim_freq.append( ( 1 / ( ( (exp_obj.single_stim_dur*exp_obj.n_shots) * exp_obj.n_groups-1 ) + ( exp_obj.inter_point_delay * exp_obj.n_groups ) ) ) *1000 )\n",
    "            \n",
    "#store and plot basic stats of datasets\n",
    "\n",
    "df = pd.DataFrame(data=list(zip(n_units, n_targets, n_targeted_cells, stim_dur, stim_freq)), columns=['n_units', 'n_targets', 'n_targeted_cells', 'stim_dur', 'stim_freq'])\n",
    "df['target_groups'] = np.resize(['random','sensory'], (14))\n",
    "print(df)\n",
    "\n",
    "for column in df.columns[:-1]:\n",
    "    plt.figure(figsize=(3,5))\n",
    "    sns.boxplot(x='target_groups', y=column, data=df, width=0.2)\n",
    "    sns.swarmplot(x='target_groups', y=column, data=df, color='k', size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make target STA traces\n",
    "\n",
    "mean_sta_amp = []\n",
    "\n",
    "for root, dirs, files in os.walk(pkl_folder):\n",
    "    for file in files:\n",
    "        pkl_path = os.path.join(pkl_folder, file)\n",
    "        print(pkl_path)\n",
    "        \n",
    "        if any(s in pkl_path for s in ['random', 'sensory']):\n",
    "#         if 'spont_sham' in pkl_path:\n",
    "            \n",
    "            with open(pkl_path, 'rb') as f:\n",
    "                exp_obj = pickle.load(f)\n",
    "            \n",
    "            sta_amp = []\n",
    "            targeted_sta = []\n",
    "\n",
    "            for cell,_ in enumerate(exp_obj.targeted_cells):\n",
    "                if exp_obj.targeted_cells[cell]==1:\n",
    "                    targeted_sta.append(exp_obj.stas[0][cell])\n",
    "                    sta_amp.append(exp_obj.sta_amplitudes[0][cell])\n",
    "                               \n",
    "            mean_sta = np.nanmean(targeted_sta,axis=0)\n",
    "            mean_sta_amp.append(np.nanmean(sta_amp,axis=0))\n",
    "            \n",
    "            plt.figure(figsize=(5,5));\n",
    "\n",
    "            for sta,_ in enumerate(targeted_sta):\n",
    "                a = range(0,len(targeted_sta[sta]))\n",
    "                b = [x/exp_obj.fps for x in a]\n",
    "                plt.plot(b, targeted_sta[sta], 'r--', lw=0.2);\n",
    "                plt.ylim((-10,90))\n",
    "            plt.plot(b, mean_sta, 'k', lw=2);\n",
    "            plt.xlabel('time (sec)')\n",
    "            plt.ylabel('Normalised change in fluorescence (dFF %)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target_sta_amp'] = mean_sta_amp\n",
    "print(df)\n",
    "\n",
    "plt.figure(figsize=(3,5))\n",
    "sns.boxplot(x='target_groups', y='target_sta_amp', data=df, width=0.2)\n",
    "sns.swarmplot(x='target_groups', y='target_sta_amp', data=df, color='k', size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make follower STA traces\n",
    "\n",
    "mean_sta_amp_neg = []\n",
    "mean_sta_amp_pos = []\n",
    "\n",
    "for root, dirs, files in os.walk(pkl_folder):\n",
    "    for file in files:\n",
    "        pkl_path = os.path.join(pkl_folder, file)\n",
    "        print(pkl_path)\n",
    "        \n",
    "        if any(s in pkl_path for s in ['random', 'sensory']):\n",
    "#         if 'spont_sham' in pkl_path:\n",
    "            \n",
    "            with open(pkl_path, 'rb') as f:\n",
    "                exp_obj = pickle.load(f)\n",
    "            \n",
    "            follower_sta_positive = []\n",
    "            sta_amp_pos = []\n",
    "            follower_sta_negative = []\n",
    "            sta_amp_neg = []\n",
    "            \n",
    "            for cell,_ in enumerate(exp_obj.targeted_cells):\n",
    "                if exp_obj.targeted_cells[cell]==0 and exp_obj.sta_amplitudes[0][cell] > 0 and cell in exp_obj.sta_sig_nomulti[0]:\n",
    "#                 if exp_obj.targeted_cells[cell]==0 and exp_obj.sta_amplitudes[0][cell] > 0:\n",
    "                    follower_sta_positive.append(exp_obj.stas[0][cell])\n",
    "                    sta_amp_pos.append(exp_obj.sta_amplitudes[0][cell])\n",
    "            \n",
    "                if exp_obj.targeted_cells[cell]==0 and exp_obj.sta_amplitudes[0][cell] < 0 and cell in exp_obj.sta_sig_nomulti[0]:\n",
    "#                 if exp_obj.targeted_cells[cell]==0 and exp_obj.sta_amplitudes[0][cell] < 0:\n",
    "                    follower_sta_negative.append(exp_obj.stas[0][cell])\n",
    "                    sta_amp_neg.append(exp_obj.sta_amplitudes[0][cell])\n",
    "                    \n",
    "            if np.shape(follower_sta_positive)[0] > 0:\n",
    "                mean_sta = np.mean(follower_sta_positive,axis=0)\n",
    "                mean_sta_amp_pos.append(np.nanmean(sta_amp_pos))\n",
    "                 \n",
    "                plt.figure(figsize=(10,5));\n",
    "                ax1 = plt.subplot(121)\n",
    "                ax2 = plt.subplot(122)\n",
    "\n",
    "                for sta,_ in enumerate(follower_sta_positive):\n",
    "                    a = range(0,len(follower_sta_positive[sta]))\n",
    "                    b = [x/exp_obj.fps for x in a]\n",
    "                    ax1.plot(b, follower_sta_positive[sta], 'r--', lw=0.2);\n",
    "                    ax1.set_ylim((-10, 20))\n",
    "                ax1.plot(b, mean_sta, 'k', lw=2);\n",
    "                plt.xlabel('time (sec)')\n",
    "                plt.ylabel('Normalised change in fluorescence (dFF %)')\n",
    "            \n",
    "            if np.shape(follower_sta_negative)[0] > 0:\n",
    "                mean_sta = np.mean(follower_sta_negative,axis=0)\n",
    "                mean_sta_amp_neg.append(np.nanmean(sta_amp_neg))\n",
    "\n",
    "                for sta,_ in enumerate(follower_sta_negative):\n",
    "                    a = range(0,len(follower_sta_negative[sta]))\n",
    "                    b = [x/exp_obj.fps for x in a]\n",
    "                    ax2.plot(b, follower_sta_negative[sta], 'b--', lw=0.2);\n",
    "                    ax2.set_ylim((-10, 20))\n",
    "                ax2.plot(b, mean_sta, 'k', lw=2);\n",
    "                plt.xlabel('time (sec)')\n",
    "                plt.ylabel('Normalised change in fluorescence (dFF %)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot sham 'follower' response amplitudes\n",
    "\n",
    "plt.figure(figsize=(3,5))\n",
    "sns.boxplot(data=mean_sta_amp_neg, width=0.2)\n",
    "sns.swarmplot(data=mean_sta_amp_neg, color='k', size=5)\n",
    "plt.ylim(-2.75, 0)\n",
    "\n",
    "plt.figure(figsize=(3,5))\n",
    "sns.boxplot(data=mean_sta_amp_pos, width=0.2)\n",
    "sns.swarmplot(data=mean_sta_amp_pos, color='k', size=5)\n",
    "plt.ylim(0, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['follower_sta_amp_+ve'] = mean_sta_amp_pos\n",
    "df['follower_sta_amp_-ve'] = mean_sta_amp_neg\n",
    "print(df)\n",
    "\n",
    "plt.figure(figsize=(3,5))\n",
    "sns.boxplot(x='target_groups', y='follower_sta_amp_+ve', data=df, width=0.2)\n",
    "sns.swarmplot(x='target_groups', y='follower_sta_amp_+ve', data=df, color='k', size=5)\n",
    "plt.ylim(0, 12)\n",
    "\n",
    "plt.figure(figsize=(3,5))\n",
    "sns.boxplot(x='target_groups', y='follower_sta_amp_-ve', data=df, width=0.2)\n",
    "sns.swarmplot(x='target_groups', y='follower_sta_amp_-ve', data=df, color='k', size=5)\n",
    "plt.ylim(-2.75, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of cells excited in s1 and s2\n",
    "\n",
    "pkl_folder = r'P:\\rlees\\pkl_files'\n",
    "\n",
    "plt.figure(figsize=(10,15))\n",
    "\n",
    "ax1 = plt.subplot(321)\n",
    "ax2 = plt.subplot(322)\n",
    "# ax3 = plt.subplot(323)\n",
    "# ax4 = plt.subplot(324)\n",
    "# ax5 = plt.subplot(325)\n",
    "# ax6 = plt.subplot(326)\n",
    "\n",
    "rand_ratio_s1_s2 = []\n",
    "sensory_ratio_s1_s2 = []\n",
    "all_trial_s1_sensory = []\n",
    "all_trial_s2_sensory = []\n",
    "all_trial_s1_random = []\n",
    "all_trial_s2_random = []\n",
    "\n",
    "for root, dirs, files in os.walk(pkl_folder):\n",
    "    for pkl_file in files:\n",
    "        pkl_path = os.path.join(pkl_folder, pkl_file)\n",
    "        print(pkl_path)\n",
    "        \n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            exp_obj = pickle.load(f)\n",
    "        \n",
    "        trial_s1_count = []\n",
    "        trial_s2_count = []\n",
    "        \n",
    "        if 'spont' not in pkl_file:\n",
    "#         if any(s in pkl_file for s in ['RL055_exp1', 'J059_exp1']):\n",
    "            \n",
    "            for trial in range(exp_obj.n_trials):\n",
    "\n",
    "                s1_count = 0\n",
    "                s2_count = 0\n",
    "\n",
    "                for cell,_ in enumerate(exp_obj.cell_id[0]):\n",
    "\n",
    "    #                 if exp_obj.single_sig[0][cell][trial] == True and exp_obj.cell_med[0][cell][1] < 400:\n",
    "                    if exp_obj.single_sig[0][cell][trial] == True and exp_obj.all_amplitudes[0][cell][trial] > 0 and exp_obj.cell_med[0][cell][1] < s2_border:\n",
    "                        s1_count += 1\n",
    "    #                 if exp_obj.single_sig[0][cell][trial] == True and exp_obj.cell_med[0][cell][1] > 450:\n",
    "                    if exp_obj.single_sig[0][cell][trial] == True and exp_obj.all_amplitudes[0][cell][trial] > 0 and exp_obj.cell_med[0][cell][1] > s2_border:\n",
    "                        s2_count += 1\n",
    "\n",
    "                trial_s1_count.append(s1_count)\n",
    "                trial_s2_count.append(s2_count)\n",
    "\n",
    "            if 'random' in pkl_file:\n",
    "#             if 'RL055' in pkl_file:\n",
    "                ax1.scatter(trial_s1_count, trial_s2_count, label=exp_obj.sheet_name, alpha=0.4)\n",
    "#                 ax3.hist(trial_s1_count, histtype='step')\n",
    "#                 ax5.hist(trial_s2_count, histtype='step')\n",
    "                try:\n",
    "                    rand_ratio_s1_s2.append([s2_count/(s1_count+0.01) for s1_count,s2_count in zip(trial_s1_count, trial_s2_count)])\n",
    "                except:\n",
    "                    print('Error in ratio calculation.')\n",
    "                all_trial_s1_random.append(trial_s1_count)\n",
    "                all_trial_s2_random.append(trial_s2_count)\n",
    "                \n",
    "            if 'sensory' in pkl_file:\n",
    "#             if 'J059' in pkl_file:\n",
    "                ax2.scatter(trial_s1_count, trial_s2_count, label=exp_obj.sheet_name, alpha=0.4)\n",
    "#                 ax4.hist(trial_s1_count, histtype='step')\n",
    "#                 ax6.hist(trial_s2_count, histtype='step')\n",
    "                try:\n",
    "                    sensory_ratio_s1_s2.append([s2_count/(s1_count+0.01) for s1_count,s2_count in zip(trial_s1_count, trial_s2_count)])\n",
    "                except:\n",
    "                    print('Error in ratio calculation.')\n",
    "                    \n",
    "                all_trial_s1_sensory.append(trial_s1_count)\n",
    "                all_trial_s2_sensory.append(trial_s2_count)\n",
    "        \n",
    "    rand_ratio_s1_s2 = [item for sublist in rand_ratio_s1_s2 for item in sublist]\n",
    "    sensory_ratio_s1_s2 = [item for sublist in sensory_ratio_s1_s2 for item in sublist]\n",
    "\n",
    "ax1.set_ylim((-5,200))\n",
    "ax2.set_ylim((-5,200))\n",
    "ax1.set_xlim((0,200))\n",
    "ax2.set_xlim((0,200))\n",
    "# ax3.set_xlim((0,200))\n",
    "# ax4.set_xlim((0,200))\n",
    "# ax5.set_xlim((0,200))\n",
    "# ax6.set_xlim((0,200))\n",
    "# ax3.set_xlim((0,100))\n",
    "# ax4.set_xlim((0,100))\n",
    "# ax5.set_xlim((0,100))\n",
    "# ax6.set_xlim((0,100))\n",
    "ax1.set_aspect('equal');\n",
    "ax2.set_aspect('equal');\n",
    "\n",
    "ax1.set_xlabel('Number of S1 cells excited')\n",
    "ax2.set_xlabel('Number of S1 cells excited')\n",
    "ax1.set_ylabel('Number of S2 cells excited')\n",
    "ax2.set_ylabel('Number of S2 cells excited')\n",
    "\n",
    "plt.figure(figsize=(5,10));\n",
    "plt.boxplot([rand_ratio_s1_s2,sensory_ratio_s1_s2]);\n",
    "plt.ylabel('Ratio of excited S2 cells to excited S1 cells');\n",
    "plt.ylim(-1,11);\n",
    "stats.wilcoxon(rand_ratio_s1_s2, sensory_ratio_s1_s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trial_s1_sensory = [cells for sublist in all_trial_s1_sensory for cells in sublist]\n",
    "all_trial_s2_sensory = [cells for sublist in all_trial_s2_sensory for cells in sublist]\n",
    "\n",
    "all_trial_s1_random = [cells for sublist in all_trial_s1_random for cells in sublist]\n",
    "all_trial_s2_random = [cells for sublist in all_trial_s2_random for cells in sublist]\n",
    "\n",
    "plt.figure(figsize=(10,15))\n",
    "ax1 = plt.subplot(321)\n",
    "ax2 = plt.subplot(322)\n",
    "\n",
    "x=all_trial_s1_sensory\n",
    "y=all_trial_s2_sensory\n",
    "\n",
    "ax1.scatter(all_trial_s1_random, all_trial_s2_random, alpha=0.2)\n",
    "z = np.polyfit(all_trial_s1_random, all_trial_s2_random, 1)\n",
    "p = np.poly1d(z)\n",
    "ax1.plot(all_trial_s1_random,p(all_trial_s1_random),'r')\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(all_trial_s1_random,all_trial_s2_random)\n",
    "slope = np.around(slope, decimals=4)\n",
    "r_value = np.around(r_value, decimals=2)\n",
    "ax1.text(70, 100, 'Slope: ' + str(slope) + '\\nr^2: ' + str(np.square(r_value)))\n",
    "\n",
    "x=all_trial_s1_random\n",
    "y=all_trial_s2_random\n",
    "\n",
    "ax2.scatter(all_trial_s1_sensory, all_trial_s2_sensory, alpha=0.2)\n",
    "z = np.polyfit(all_trial_s1_sensory, all_trial_s2_sensory, 1)\n",
    "p = np.poly1d(z)\n",
    "ax2.plot(all_trial_s1_sensory,p(all_trial_s1_sensory),'r')\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(all_trial_s1_sensory,all_trial_s2_sensory)\n",
    "slope = np.around(slope, decimals=4)\n",
    "r_value = np.around(r_value, decimals=2)\n",
    "ax2.text(70, 100, 'Slope: ' + str(slope) + '\\nr^2: ' + str(np.square(r_value)))\n",
    "\n",
    "ax1.set_ylim((-5,200))\n",
    "ax2.set_ylim((-5,200))\n",
    "ax1.set_xlim((0,200))\n",
    "ax2.set_xlim((0,200))\n",
    "ax1.set_aspect('equal');\n",
    "ax2.set_aspect('equal');\n",
    "\n",
    "ax1.set_xlabel('Number of S1 cells excited');\n",
    "ax2.set_xlabel('Number of S1 cells excited');\n",
    "ax1.set_ylabel('Number of S2 cells excited');\n",
    "ax2.set_ylabel('Number of S2 cells excited');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of cells excited in s1 and s2 STA\n",
    "\n",
    "# Need to find number of cells that have significant STA response and are at certain spatial location\n",
    "# I have: \n",
    "# *List of cell_ids that were significant units = sta_sig\n",
    "# *Locations of cells in cell_med[1] (x coord)\n",
    "#\n",
    "# Use cell_id to find each sta_sig index in original list of all cells (not id from s2p, just position in list)\n",
    "# This list is therefore a list of indices that are cells with significant STA response\n",
    "# Use said list to check if cell was in correct location\n",
    "\n",
    "pkl_folder = r'P:\\rlees\\pkl_files'\n",
    "\n",
    "plt.figure(figsize=(10,15))\n",
    "\n",
    "ax1 = plt.subplot(321)\n",
    "ax2 = plt.subplot(322)\n",
    "\n",
    "for root, dirs, files in os.walk(pkl_folder):\n",
    "    for pkl_file in files:\n",
    "        pkl_path = os.path.join(pkl_folder, pkl_file)\n",
    "        print(pkl_path)\n",
    "        \n",
    "        if 'spont' not in pkl_file:\n",
    "        \n",
    "            with open(pkl_path, 'rb') as f:\n",
    "                exp_obj = pickle.load(f)\n",
    "            \n",
    "            sig_units = [i for i,cell in enumerate(exp_obj.cell_id[0]) if cell in exp_obj.sta_sig[0]]\n",
    "#             sig_units = [i for i,cell in enumerate(exp_obj.cell_id[0]) if cell in exp_obj.sta_sig_nomulti[0]]\n",
    "#             sig_units = [i for i,_ in enumerate(exp_obj.cell_id[0])] # no significance testing\n",
    "            n_s2_cells = len([cell for cell in sig_units if exp_obj.cell_med[0][cell][1] > s2_border and exp_obj.sta_amplitudes[0][cell] > 0])\n",
    "            n_s1_cells = len([cell for cell in sig_units if exp_obj.cell_med[0][cell][1] < s2_border and exp_obj.sta_amplitudes[0][cell] > 0])\n",
    "#             n_target_cells = len([cell for cell in sig_units if exp_obj.targeted_cells[cell]==1 and exp_obj.sta_amplitudes[0][cell] > 0])\n",
    "    \n",
    "            if 'random' in pkl_file:\n",
    "                ax1.scatter(n_s1_cells, n_s2_cells, label=exp_obj.sheet_name)\n",
    "#                 ax1.scatter(n_target_cells, n_s2_cells, label=exp_obj.sheet_name)\n",
    "\n",
    "            if 'sensory' in pkl_file:\n",
    "                ax2.scatter(n_s1_cells, n_s2_cells, label=exp_obj.sheet_name)\n",
    "#                 ax2.scatter(n_target_cells, n_s2_cells, label=exp_obj.sheet_name)\n",
    "\n",
    "ax1.set_xlim((-5,300))\n",
    "ax2.set_xlim((-5,300))\n",
    "ax1.set_ylim((-1,20))\n",
    "ax2.set_ylim((-1,20))\n",
    "# ax1.set_aspect('equal');\n",
    "# ax2.set_aspect('equal');\n",
    "\n",
    "ax1.set_xlabel('Number of S1 cells excited');\n",
    "ax2.set_xlabel('Number of S1 cells excited');\n",
    "ax1.set_ylabel('Number of S2 cells excited');\n",
    "ax2.set_ylabel('Number of S2 cells excited');\n",
    "ax1.set_title('Random targets');\n",
    "ax2.set_title('Similarly-tuned targets');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(pkl_folder):\n",
    "    for pkl_file in files:\n",
    "        pkl_path = os.path.join(pkl_folder, pkl_file)\n",
    "        print(pkl_path)\n",
    "        \n",
    "        if any(s in pkl_path for s in ['random', 'sensory', 'sham']):\n",
    "        \n",
    "            with open(pkl_path, 'rb') as f:\n",
    "                exp_obj = pickle.load(f)\n",
    "\n",
    "            exp_obj.sta_sig_nomulti = []\n",
    "\n",
    "            for plane in range(exp_obj.n_planes):\n",
    "\n",
    "                p_vals = [t[1] for t in exp_obj.t_tests[plane]]\n",
    "\n",
    "                sig_units = []\n",
    "\n",
    "                for i,p in enumerate(p_vals):\n",
    "                    if p < 0.05:\n",
    "                        unit_index = exp_obj.cell_id[plane][i]\n",
    "                        sig_units.append(unit_index) #significant units\n",
    "\n",
    "                exp_obj.sta_sig_nomulti.append(sig_units)  \n",
    "                \n",
    "                with open(pkl_path, 'wb') as f:\n",
    "                    pickle.dump(exp_obj, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proportion of cells excited in s1 and s2\n",
    "\n",
    "pkl_folder = r'P:\\rlees\\pkl_files'\n",
    "\n",
    "plt.figure(figsize=(10,15))\n",
    "\n",
    "ax1 = plt.subplot(321)\n",
    "ax2 = plt.subplot(322)\n",
    "# ax3 = plt.subplot(323)\n",
    "# ax4 = plt.subplot(324)\n",
    "# ax5 = plt.subplot(325)\n",
    "# ax6 = plt.subplot(326)\n",
    "\n",
    "for root, dirs, files in os.walk(pkl_folder):\n",
    "    for pkl_file in files:\n",
    "        pkl_path = os.path.join(pkl_folder, pkl_file)\n",
    "        print(pkl_path)\n",
    "        \n",
    "        if 'spont' not in pkl_file:\n",
    "            \n",
    "            with open(pkl_path, 'rb') as f:\n",
    "                exp_obj = pickle.load(f)\n",
    "\n",
    "            trial_s1_count = []\n",
    "            trial_s2_count = []\n",
    "\n",
    "            for trial in range(exp_obj.n_trials):\n",
    "\n",
    "                s1_count = 0\n",
    "                s2_count = 0\n",
    "\n",
    "                for cell,_ in enumerate(exp_obj.cell_id[0]):\n",
    "\n",
    "    #                 if exp_obj.single_sig[0][cell][trial] == True and exp_obj.cell_med[0][cell][1] < 400:\n",
    "                    if exp_obj.single_sig[0][cell][trial] == True and exp_obj.all_amplitudes[0][cell][trial] > 0 and exp_obj.cell_med[0][cell][1] < s2_border:\n",
    "                        s1_count += 1\n",
    "    #                 if exp_obj.single_sig[0][cell][trial] == True and exp_obj.cell_med[0][cell][1] > 450:\n",
    "                    if exp_obj.single_sig[0][cell][trial] == True and exp_obj.all_amplitudes[0][cell][trial] > 0 and exp_obj.cell_med[0][cell][1] > s2_border:\n",
    "                        s2_count += 1\n",
    "\n",
    "                trial_s1_count.append(s1_count)\n",
    "                trial_s2_count.append(s2_count)\n",
    "            \n",
    "            total_s1_cells = len([x for y,x in exp_obj.cell_med[0][:] if x < s2_border])\n",
    "            total_s2_cells = len([x for y,x in exp_obj.cell_med[0][:] if x > s2_border])\n",
    "            \n",
    "            percent_s1_count = [(x/total_s1_cells)*100 for x in trial_s1_count]\n",
    "            percent_s2_count = [(x/total_s2_cells)*100 for x in trial_s2_count]\n",
    "            \n",
    "            if 'random' in pkl_file:\n",
    "                ax1.scatter(percent_s1_count, percent_s2_count, label=exp_obj.sheet_name, alpha=0.4)\n",
    "#                 ax3.hist(percent_s1_count, histtype='step')\n",
    "#                 ax5.hist(percent_s2_count, histtype='step')\n",
    "            if 'sensory' in pkl_file:\n",
    "                ax2.scatter(percent_s1_count, percent_s2_count, label=exp_obj.sheet_name, alpha=0.4)\n",
    "#                 ax4.hist(percent_s1_count, histtype='step')\n",
    "#                 ax6.hist(percent_s2_count, histtype='step')\n",
    "\n",
    "ax1.set_ylim((-.5,50))\n",
    "ax2.set_ylim((-.5,50))\n",
    "ax1.set_xlim((0,65))\n",
    "ax2.set_xlim((0,65))\n",
    "# ax3.set_xlim((0,10))\n",
    "# ax4.set_xlim((0,10))\n",
    "# ax5.set_xlim((0,10))\n",
    "# ax6.set_xlim((0,10))\n",
    "# ax3.set_ylim((0,100))\n",
    "# ax4.set_ylim((0,100))\n",
    "# ax5.set_ylim((0,100))\n",
    "# ax6.set_ylim((0,100))\n",
    "ax1.set_aspect('equal');\n",
    "ax2.set_aspect('equal');\n",
    "\n",
    "ax1.set_xlabel('Proportion of S1 cells excited')\n",
    "ax2.set_xlabel('Proportion of S1 cells excited')\n",
    "ax1.set_ylabel('Proportion of S2 cells excited')\n",
    "ax2.set_ylabel('Proportion of S2 cells excited')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of cells excited in s1 and s2 for spont_sham data\n",
    "\n",
    "pkl_folder = r'P:\\rlees\\pkl_files'\n",
    "\n",
    "plt.figure(figsize=(10,15))\n",
    "\n",
    "ax1 = plt.subplot(321)\n",
    "ax2 = plt.subplot(322)\n",
    "\n",
    "for root, dirs, files in os.walk(pkl_folder):\n",
    "    for pkl_file in files:\n",
    "        pkl_path = os.path.join(pkl_folder, pkl_file)\n",
    "        print(pkl_path)\n",
    "        \n",
    "        if 'spont_sham' in pkl_file:\n",
    "            \n",
    "            with open(pkl_path, 'rb') as f:\n",
    "                exp_obj = pickle.load(f)\n",
    "\n",
    "            trial_s1_count = []\n",
    "            trial_s2_count = []\n",
    "         \n",
    "            for trial in range(exp_obj.n_trials):\n",
    "\n",
    "                s1_count = 0\n",
    "                s2_count = 0\n",
    "\n",
    "                for cell,_ in enumerate(exp_obj.cell_id[0]):\n",
    "\n",
    "    #                 if exp_obj.single_sig[0][cell][trial] == True and exp_obj.cell_med[0][cell][1] < 400:\n",
    "                    if exp_obj.single_sig[0][cell][trial] == True and exp_obj.all_amplitudes[0][cell][trial] > 0 and exp_obj.cell_med[0][cell][1] < s2_border:\n",
    "                        s1_count += 1\n",
    "    #                 if exp_obj.single_sig[0][cell][trial] == True and exp_obj.cell_med[0][cell][1] > 450:\n",
    "                    if exp_obj.single_sig[0][cell][trial] == True and exp_obj.all_amplitudes[0][cell][trial] > 0 and exp_obj.cell_med[0][cell][1] > s2_border:\n",
    "                        s2_count += 1\n",
    "\n",
    "                trial_s1_count.append(s1_count)\n",
    "                trial_s2_count.append(s2_count)\n",
    "            \n",
    "            total_s1_cells = len([x for y,x in exp_obj.cell_med[0][:] if x < s2_border])\n",
    "            total_s2_cells = len([x for y,x in exp_obj.cell_med[0][:] if x > s2_border])\n",
    "            \n",
    "            percent_s1_count = [(x/total_s1_cells)*100 for x in trial_s1_count]\n",
    "            percent_s2_count = [(x/total_s2_cells)*100 for x in trial_s2_count]\n",
    "            \n",
    "            if 'RL055' in pkl_file:\n",
    "                ax1.scatter(trial_s1_count, trial_s2_count, label=exp_obj.sheet_name, alpha=0.4)\n",
    "#                 ax3.hist(percent_s1_count, histtype='step')\n",
    "#                 ax5.hist(percent_s2_count, histtype='step')\n",
    "                \n",
    "                # calc the trendline\n",
    "                z = np.polyfit(trial_s1_count, trial_s2_count, 1)\n",
    "                p = np.poly1d(z)\n",
    "                ax1.plot(trial_s1_count,p(trial_s1_count),'r')\n",
    "                slope, intercept, r_value, p_value, std_err = stats.linregress(trial_s1_count,trial_s2_count)\n",
    "                slope = np.around(slope, decimals=4)\n",
    "                r_value = np.around(r_value, decimals=2)\n",
    "                ax1.text(70, 100, 'Slope: ' + str(slope) + '\\nr^2: ' + str(np.square(r_value))) \n",
    "                \n",
    "            if 'J059' in pkl_file:\n",
    "                ax2.scatter(trial_s1_count, trial_s2_count, label=exp_obj.sheet_name, alpha=0.4)\n",
    "#                 ax4.hist(percent_s1_count, histtype='step')\n",
    "#                 ax6.hist(percent_s2_count, histtype='step')\n",
    "                \n",
    "                # calc the trendline\n",
    "                z = np.polyfit(trial_s1_count, trial_s2_count, 1)\n",
    "                p = np.poly1d(z)\n",
    "                ax2.plot(trial_s1_count,p(trial_s1_count),'r')\n",
    "                slope, intercept, r_value, p_value, std_err = stats.linregress(trial_s1_count,trial_s2_count)\n",
    "                slope = np.around(slope, decimals=4)\n",
    "                r_value = np.around(r_value, decimals=2)\n",
    "                ax2.text(70, 100, 'Slope: ' + str(slope) + '\\nr^2: ' + str(np.square(r_value))) \n",
    "\n",
    "ax1.set_ylim((-5,200));\n",
    "ax2.set_ylim((-5,200));\n",
    "ax1.set_xlim((-5,200));\n",
    "ax2.set_xlim((-5,200));\n",
    "ax1.set_aspect('equal');\n",
    "ax2.set_aspect('equal');\n",
    "\n",
    "ax1.set_xlabel('Number of S1 cells excited');\n",
    "ax2.set_xlabel('Number of S1 cells excited');\n",
    "ax1.set_ylabel('Number of S2 cells excited');\n",
    "ax2.set_ylabel('Number of S2 cells excited');\n",
    "ax1.set_title('RL055');\n",
    "ax2.set_title('J059');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proportion of cells excited in s1 and s2 for spont_sham data\n",
    "\n",
    "pkl_folder = r'P:\\rlees\\pkl_files'\n",
    "\n",
    "plt.figure(figsize=(10,15))\n",
    "\n",
    "ax1 = plt.subplot(321)\n",
    "ax2 = plt.subplot(322)\n",
    "\n",
    "for root, dirs, files in os.walk(pkl_folder):\n",
    "    for pkl_file in files:\n",
    "        pkl_path = os.path.join(pkl_folder, pkl_file)\n",
    "        print(pkl_path)\n",
    "        \n",
    "        if 'spont_sham' in pkl_file:\n",
    "            \n",
    "            with open(pkl_path, 'rb') as f:\n",
    "                exp_obj = pickle.load(f)\n",
    "\n",
    "            trial_s1_count = []\n",
    "            trial_s2_count = []\n",
    "         \n",
    "            for trial in range(exp_obj.n_trials):\n",
    "\n",
    "                s1_count = 0\n",
    "                s2_count = 0\n",
    "\n",
    "                for cell,_ in enumerate(exp_obj.cell_id[0]):\n",
    "\n",
    "    #                 if exp_obj.single_sig[0][cell][trial] == True and exp_obj.cell_med[0][cell][1] < 400:\n",
    "                    if exp_obj.single_sig[0][cell][trial] == True and exp_obj.all_amplitudes[0][cell][trial] > 0 and exp_obj.cell_med[0][cell][1] < s2_border:\n",
    "                        s1_count += 1\n",
    "    #                 if exp_obj.single_sig[0][cell][trial] == True and exp_obj.cell_med[0][cell][1] > 450:\n",
    "                    if exp_obj.single_sig[0][cell][trial] == True and exp_obj.all_amplitudes[0][cell][trial] > 0 and exp_obj.cell_med[0][cell][1] > s2_border:\n",
    "                        s2_count += 1\n",
    "\n",
    "                trial_s1_count.append(s1_count)\n",
    "                trial_s2_count.append(s2_count)\n",
    "            \n",
    "            total_s1_cells = len([x for y,x in exp_obj.cell_med[0][:] if x < s2_border])\n",
    "            total_s2_cells = len([x for y,x in exp_obj.cell_med[0][:] if x > s2_border])\n",
    "            \n",
    "            percent_s1_count = [(x/total_s1_cells)*100 for x in trial_s1_count]\n",
    "            percent_s2_count = [(x/total_s2_cells)*100 for x in trial_s2_count]\n",
    "            \n",
    "            x = percent_s1_count\n",
    "            y = percent_s2_count\n",
    "            \n",
    "            if 'RL055' in pkl_file:\n",
    "                ax1.scatter(x, y, label=exp_obj.sheet_name, alpha=0.4)\n",
    "#                 ax3.hist(percent_s1_count, histtype='step')\n",
    "#                 ax5.hist(percent_s2_count, histtype='step')\n",
    "                \n",
    "                # calc the trendline\n",
    "                z = np.polyfit(x, y, 1)\n",
    "                p = np.poly1d(z)\n",
    "                ax1.plot(x,p(x),'r')\n",
    "                slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "                slope = np.around(slope, decimals=4)\n",
    "                r_value = np.around(r_value, decimals=2)\n",
    "                ax1.text(50, 50, 'Slope: ' + str(slope) + '\\nr^2: ' + str(np.square(r_value))) \n",
    "                \n",
    "            if 'J059' in pkl_file:\n",
    "                ax2.scatter(x, y, label=exp_obj.sheet_name, alpha=0.4)\n",
    "#                 ax4.hist(percent_s1_count, histtype='step')\n",
    "#                 ax6.hist(percent_s2_count, histtype='step')\n",
    "                \n",
    "                # calc the trendline\n",
    "                z = np.polyfit(x, y, 1)\n",
    "                p = np.poly1d(z)\n",
    "                ax2.plot(x,p(x),'r')\n",
    "                slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "                slope = np.around(slope, decimals=4)\n",
    "                r_value = np.around(r_value, decimals=2)\n",
    "                ax2.text(50, 50, 'Slope: ' + str(slope) + '\\nr^2: ' + str(np.square(r_value))) \n",
    "\n",
    "ax1.set_ylim((-5,100));\n",
    "ax2.set_ylim((-5,100));\n",
    "ax1.set_xlim((-5,100));\n",
    "ax2.set_xlim((-5,100));\n",
    "ax1.set_aspect('equal');\n",
    "ax2.set_aspect('equal');\n",
    "\n",
    "ax1.set_xlabel('Proportion of S1 cells excited');\n",
    "ax2.set_xlabel('Proportion of S1 cells excited');\n",
    "ax1.set_ylabel('Proportion of S2 cells excited');\n",
    "ax2.set_ylabel('Proportion of S2 cells excited');\n",
    "ax1.set_title('RL055');\n",
    "ax2.set_title('J059');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate STA postage of cells\n",
    "\n",
    "# Maybe make the STA movie from the frames that are relevant, adding it to the first stack. \n",
    "# I.e. Load stack 1, add stack 2... add stack n and then divide by the number of trials to get the STA\n",
    "# Save the STA for later cropping using ROIs\n",
    "\n",
    "# Alternatively for each trial (as an additional argument) look at the postage stamp for that trial\n",
    "# to see if it look like a cell increasing in intensity\n",
    "\n",
    "pkl_folder = r'P:\\rlees\\pkl_files'\n",
    "plane = 0\n",
    "\n",
    "# Need to find bounding box of cell from x and y pix extremes and make a border around that to crop STA\n",
    "# ORIGIN = top-left, y = 0, x = 0\n",
    "\n",
    "for root, dirs, files in os.walk(pkl_folder):\n",
    "    for file in files:\n",
    "        pkl_path = os.path.join(pkl_folder, file)\n",
    "        \n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            exp_obj = pickle.load(f)\n",
    "        \n",
    "        print(exp_obj.tiff_path)\n",
    "        \n",
    "        try:\n",
    "            output_dir = os.path.join(exp_obj.tiff_path, 'targ_cells_dff')\n",
    "            os.mkdir(output_dir)\n",
    "        except:\n",
    "            print('Could not make directory.')\n",
    "            \n",
    "        for trial in range(exp_obj.n_trials):\n",
    "\n",
    "            for cell,_ in enumerate(exp_obj.cell_id[0]):\n",
    "\n",
    "                if exp_obj.targeted_cells[cell]==1 and exp_obj.single_sig[0][cell][trial] == True and exp_obj.all_amplitudes[0][cell][trial] > 0:\n",
    "#                 if exp_obj.single_sig[0][cell][trial] == True and exp_obj.all_amplitudes[0][cell][trial] > 20:\n",
    "\n",
    "                    min_x = np.min(exp_obj.cell_x[plane][cell])\n",
    "                    max_x = np.max(exp_obj.cell_x[plane][cell])\n",
    "                    width_cell = max_x - min_x\n",
    "\n",
    "                    min_y = np.min(exp_obj.cell_y[plane][cell])\n",
    "                    max_y = np.max(exp_obj.cell_y[plane][cell])\n",
    "                    height_cell = max_y - min_y\n",
    "\n",
    "                    bd_x_start = (min_x - 10)\n",
    "                    bd_width = width_cell + 20\n",
    "                    bd_x_stop = bd_x_start + bd_width\n",
    "                    \n",
    "                    if bd_x_start < 0:\n",
    "                        bd_x_start = 0\n",
    "                        \n",
    "                    if bd_x_stop > exp_obj.frame_x:\n",
    "                        bd_x_stop = exp_obj.frame_x\n",
    "                        \n",
    "                    bd_y_start = (min_y - 10)\n",
    "                    bd_height = height_cell + 20\n",
    "                    bd_y_stop = bd_y_start + bd_height\n",
    "                    \n",
    "                    if bd_y_start < 0:\n",
    "                        bd_y_start = 0\n",
    "                        \n",
    "                    if bd_y_stop > exp_obj.frame_y:\n",
    "                        bd_y_stop = exp_obj.frame_y\n",
    "\n",
    "                    frame_start = exp_obj.stim_start_frames[plane][trial]\n",
    "                    trial_start = frame_start - exp_obj.pre_frames\n",
    "                    trial_end = frame_start + exp_obj.pre_frames + int(exp_obj.stim_dur/exp_obj.fps)\n",
    "\n",
    "                    for file in os.listdir(exp_obj.tiff_path):\n",
    "                        if '.tif' in file:\n",
    "                            tiff_file = os.path.join(exp_obj.tiff_path, file)\n",
    "                            trial_stack = tf.imread(tiff_file, key=range(trial_start,trial_end))\n",
    "\n",
    "                            trial_baseline = trial_stack[: exp_obj.pre_frames, :, :]\n",
    "                            baseline_avg = np.mean(trial_baseline, 0)\n",
    "\n",
    "                            df_stack = trial_stack - baseline_avg\n",
    "                            dff_stack = df_stack/baseline_avg * 100\n",
    "                            dff_stack = dff_stack.astype('uint32')\n",
    "\n",
    "                            cell_stack = dff_stack[-10:,bd_y_start:bd_y_stop, bd_x_start:bd_x_stop]\n",
    "                            break\n",
    "\n",
    "                    output_path = os.path.join(exp_obj.tiff_path, 'targ_cells_dff', file + '_plane' + str(plane) + '_cell' + str(cell) + '_trial' + str(trial) + '.tif')\n",
    "                    tf.imwrite(output_path, cell_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make and save STA of trials where lots of S2 cells go off to see what is happening as sanity check\n",
    "\n",
    "plane = 0\n",
    "pkl_folder = r'P:\\rlees\\pkl_files'\n",
    "\n",
    "for root, dirs, files in os.walk(pkl_folder):\n",
    "    for file in files:\n",
    "        pkl_path = os.path.join(pkl_folder, file)\n",
    "        print(pkl_path)\n",
    "        \n",
    "        if any(s in pkl_path for s in ['random', 'sensory', 'sham']):\n",
    "            with open(pkl_path, 'rb') as f:\n",
    "                exp_obj = pickle.load(f)\n",
    "\n",
    "            try:\n",
    "                output_dir = os.path.join(exp_obj.tiff_path, 'sta_many_s2_cells')\n",
    "                os.mkdir(output_dir)\n",
    "            except:\n",
    "                print('Could not make directory.')\n",
    "\n",
    "            for trial in range(exp_obj.n_trials):\n",
    "\n",
    "                s1_count = 0\n",
    "                s2_count = 0\n",
    "\n",
    "                for cell,_ in enumerate(exp_obj.cell_id[0]):\n",
    "\n",
    "                    if exp_obj.single_sig[0][cell][trial] == True and exp_obj.all_amplitudes[0][cell][trial] > 0 and exp_obj.cell_med[0][cell][1] < s2_border:\n",
    "                        s1_count += 1\n",
    "\n",
    "                    if exp_obj.single_sig[0][cell][trial] == True and exp_obj.all_amplitudes[0][cell][trial] > 0 and exp_obj.cell_med[0][cell][1] > s2_border:\n",
    "                        s2_count += 1\n",
    "\n",
    "                if s2_count > 20:\n",
    "\n",
    "                    frame_start = exp_obj.stim_start_frames[plane][trial]\n",
    "                    trial_start = frame_start - exp_obj.pre_frames\n",
    "                    trial_end = frame_start + exp_obj.pre_frames + int(exp_obj.stim_dur/exp_obj.fps)\n",
    "\n",
    "                    for file in os.listdir(exp_obj.tiff_path):\n",
    "                        if '.tif' in file:\n",
    "                            tiff_file = os.path.join(exp_obj.tiff_path, file)\n",
    "                            trial_stack = tf.imread(tiff_file, key=range(trial_start,trial_end))\n",
    "\n",
    "                            trial_baseline = trial_stack[: exp_obj.pre_frames, :, :]\n",
    "                            baseline_avg = np.mean(trial_baseline, 0)\n",
    "\n",
    "                            df_stack = trial_stack - baseline_avg\n",
    "                            dff_stack = df_stack/baseline_avg * 100\n",
    "                            dff_stack = dff_stack.astype('uint32')\n",
    "#                             dff_stack = dff_stack[-10:,:,:]\n",
    "\n",
    "                            break\n",
    "\n",
    "                    output_path = os.path.join(output_dir, file + '_plane' + str(plane) + '_trial' + str(trial) + '_' + str(s2_count) + 'cells.tif')\n",
    "                    tf.imwrite(output_path, dff_stack)\n",
    "                    print(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def points_in_circle_np(radius, x0=0, y0=0, ):\n",
    "    x_ = np.arange(x0 - radius - 1, x0 + radius + 1, dtype=int)\n",
    "    y_ = np.arange(y0 - radius - 1, y0 + radius + 1, dtype=int)\n",
    "    x, y = np.where((x_[:,np.newaxis] - x0)**2 + (y_ - y0)**2 <= radius**2)\n",
    "    for x, y in zip(x_[x], y_[y]):\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make STA of target location (see photostim resolution?)\n",
    "\n",
    "pkl_folder = r'P:\\rlees\\pkl_files'\n",
    "plane = 0\n",
    "\n",
    "for root, dirs, files in os.walk(pkl_folder):\n",
    "    for file in files:\n",
    "        pkl_path = os.path.join(pkl_folder, file)\n",
    "        print(pkl_path)\n",
    "        \n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            exp_obj = pickle.load(f)\n",
    "        \n",
    "        try:\n",
    "            output_dir = os.path.join(exp_obj.tiff_path, 'targets_dff')\n",
    "            os.mkdir(output_dir)\n",
    "        except:\n",
    "            print('Could not make directory.')\n",
    "            \n",
    "        for i,target in enumerate(exp_obj.target_coords):\n",
    "            \n",
    "            target_stack = np.empty((0,10,40,40), dtype=np.uint32)\n",
    "            \n",
    "            for trial in range(exp_obj.n_trials):\n",
    "                \n",
    "                bd_x_start = (target[0] - 10)\n",
    "                bd_width = 40\n",
    "                bd_x_stop = bd_x_start + bd_width\n",
    "\n",
    "                bd_y_start = (target[1] - 10)\n",
    "                bd_height = 40\n",
    "                bd_y_stop = bd_y_start + bd_height\n",
    "\n",
    "                frame_start = exp_obj.stim_start_frames[plane][trial]\n",
    "                trial_start = frame_start - exp_obj.pre_frames\n",
    "                trial_end = frame_start + exp_obj.pre_frames + int(exp_obj.stim_dur/exp_obj.fps)\n",
    "\n",
    "                for file in os.listdir(exp_obj.tiff_path):\n",
    "                    if '.tif' in file:\n",
    "                        tiff_file = os.path.join(exp_obj.tiff_path, file)\n",
    "                        trial_stack = tf.imread(tiff_file, key=range(trial_start,trial_end))\n",
    "\n",
    "                        trial_baseline = trial_stack[: exp_obj.pre_frames, :, :]\n",
    "                        baseline_avg = np.mean(trial_baseline, 0)\n",
    "\n",
    "                        df_stack = trial_stack - baseline_avg\n",
    "                        dff_stack = df_stack/baseline_avg * 100\n",
    "                        dff_stack = dff_stack.astype('uint32')\n",
    "\n",
    "                        crop_stack = dff_stack[-10:,bd_y_start:bd_y_stop, bd_x_start:bd_x_stop]\n",
    "                        crop_stack = np.expand_dims(crop_stack, axis=0)\n",
    "                        target_stack = np.append(target_stack, crop_stack, axis=0)\n",
    "                        break\n",
    "\n",
    "            output_path = os.path.join(exp_obj.tiff_path, 'targets_dff', file + '_plane' + str(plane) + '_target' + str(i) + '.tif')\n",
    "            tf.imwrite(output_path, target_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the proportion of targeted cells that responded (significantly) across trials,\n",
    "# does it hover at same value or fluctuate?\n",
    "\n",
    "all_prop_targ_resp = []\n",
    "all_n_targ_resp = []\n",
    "all_targ_amps = []\n",
    "\n",
    "all_prop_s2_exc = []\n",
    "all_n_s2_exc = []\n",
    "\n",
    "all_prop_s2_inh = []\n",
    "all_n_s2_inh = []\n",
    "\n",
    "all_s2_amps = []\n",
    "\n",
    "for root, dirs, files in os.walk(pkl_folder):\n",
    "    for file in files:\n",
    "        pkl_path = os.path.join(pkl_folder, file)\n",
    "        print(pkl_path)\n",
    "                \n",
    "        if any(s in pkl_path for s in ['random', 'sensory']):\n",
    "#         if 'spont_sham' in pkl_path:\n",
    "           \n",
    "            with open(pkl_path, 'rb') as f:\n",
    "                exp_obj = pickle.load(f)\n",
    "        \n",
    "            n_targeted_cells = len([x for x in exp_obj.targeted_cells if x == 1])\n",
    "\n",
    "            n_s2_cells = len([x for y,x in exp_obj.cell_med[0][:] if x > s2_border])\n",
    "\n",
    "            for trial in range(exp_obj.n_trials):\n",
    "                num_targets_exc = len([i for i,target in enumerate(exp_obj.targeted_cells) if target == 1 and exp_obj.all_amplitudes[0][i][trial] > 0 and exp_obj.single_sig[0][i][trial]])\n",
    "                proportion_targets = num_targets_exc/n_targeted_cells\n",
    "                \n",
    "                trial_targ_amps = [exp_obj.all_amplitudes[0][i][trial] for i,target in enumerate(exp_obj.targeted_cells) if target == 1 and exp_obj.single_sig[0][i][trial]]\n",
    "                all_targ_amps.append(trial_targ_amps)\n",
    "                \n",
    "                all_prop_targ_resp.append(proportion_targets)\n",
    "                all_n_targ_resp.append(num_targets_exc)\n",
    "\n",
    "                num_s2_exc = len([i for i,_ in enumerate(exp_obj.cell_id[0]) if exp_obj.all_amplitudes[0][i][trial] > 0 and exp_obj.single_sig[0][i][trial] and exp_obj.cell_med[0][i][1] > s2_border])\n",
    "                proportion_s2_exc = num_s2_exc/n_s2_cells\n",
    "                num_s2_inh = len([i for i,_ in enumerate(exp_obj.cell_id[0]) if exp_obj.all_amplitudes[0][i][trial] < 0 and exp_obj.single_sig[0][i][trial] and exp_obj.cell_med[0][i][1] > s2_border])\n",
    "                proportion_s2_inh = num_s2_inh/n_s2_cells\n",
    "                \n",
    "                trial_s2_amps = [exp_obj.all_amplitudes[0][i][trial] for i in range(exp_obj.n_units[0]) if exp_obj.single_sig[0][i][trial] and exp_obj.cell_med[0][i][1] > s2_border]\n",
    "                all_s2_amps.append(trial_s2_amps)\n",
    "                \n",
    "                all_prop_s2_exc.append(proportion_s2_exc)\n",
    "                all_prop_s2_inh.append(proportion_s2_inh)\n",
    "                all_n_s2_exc.append(num_s2_exc)\n",
    "                all_n_s2_inh.append(num_s2_inh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot number of exc/inh in cells over trials \n",
    "\n",
    "fig, ax = plt.subplots(nrows=7, ncols=2, figsize=(10,20))\n",
    "\n",
    "i=0\n",
    "\n",
    "for row in ax:\n",
    "    for col in row:\n",
    "        y = all_n_s2_inh[i:i+100]\n",
    "        x = all_n_targ_resp[i:i+100]\n",
    "        col.scatter(x, y, c='b', alpha=0.5)\n",
    "        \n",
    "        # calc the trendline\n",
    "        z = np.polyfit(x, y, 1)\n",
    "        p = np.poly1d(z)\n",
    "        col.plot(x,p(x),'b')\n",
    "        \n",
    "        y = all_n_s2_exc[i:i+100]\n",
    "        x = all_n_targ_resp[i:i+100]\n",
    "        col.scatter(x, y, c='r', alpha=0.5)\n",
    "        \n",
    "        # calc the trendline\n",
    "        z = np.polyfit(x, y, 1)\n",
    "        p = np.poly1d(z)\n",
    "        col.plot(x,p(x),'r')\n",
    "        \n",
    "        col.set_xlim((0,65))\n",
    "        col.set_ylim((0,80))\n",
    "        i+=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot proportion of exc/inh in cells over trials \n",
    "\n",
    "fig, ax = plt.subplots(nrows=7, ncols=2, figsize=(10,20))\n",
    "\n",
    "i=0\n",
    "\n",
    "for row in ax:\n",
    "    for col in row:\n",
    "        x = all_prop_targ_resp[i:i+100]\n",
    "        y = all_prop_s2_inh[i:i+100]\n",
    "        col.scatter(x, y, c='b', alpha=0.5)\n",
    "        \n",
    "        # calc the trendline\n",
    "        z = np.polyfit(x, y, 1)\n",
    "        p = np.poly1d(z)\n",
    "        col.plot(x,p(x),'b')\n",
    "        \n",
    "        x = all_prop_targ_resp[i:i+100]\n",
    "        y = all_prop_s2_exc[i:i+100]\n",
    "        col.scatter(x, y, c='r', alpha=0.5)\n",
    "        \n",
    "        # calc the trendline\n",
    "        z = np.polyfit(x, y, 1)\n",
    "        p = np.poly1d(z)\n",
    "        col.plot(x,p(x),'r')\n",
    "        \n",
    "        col.set_xlim((0,1))\n",
    "        col.set_ylim((0,.45))\n",
    "        i+=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=7, ncols=2, figsize=(10,15))\n",
    "\n",
    "i=0\n",
    "\n",
    "for row in ax:\n",
    "    for col in row:\n",
    "        x = all_targ_amps[i:i+100]\n",
    "        y = all_s2_amps[i:i+100]\n",
    "\n",
    "        x_mean = [np.sum(sublist) for sublist in x]\n",
    "        y_mean = [np.sum(sublist) for sublist in y]\n",
    "        \n",
    "        col.scatter(x_mean, y_mean, c='k', alpha=0.5)\n",
    "\n",
    "        # calc the trendline\n",
    "        z = np.polyfit(x_mean, y_mean, 1)\n",
    "        p = np.poly1d(z)\n",
    "        col.plot(x_mean,p(x_mean),'k')\n",
    "        \n",
    "        col.set_xlim((-100,7000))\n",
    "        col.set_ylim((-2000,7500))\n",
    "        i+=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10,5))\n",
    "\n",
    "i=0\n",
    "\n",
    "exc_norm_x = []\n",
    "exc_norm_y = []\n",
    "inh_norm_x = []\n",
    "inh_norm_y = []\n",
    "\n",
    "# for row in ax:\n",
    "#     for col in row:\n",
    "for session in range(14):\n",
    "    x = all_n_targ_resp[i:i+100]\n",
    "    y = all_n_s2_inh[i:i+100]\n",
    "    \n",
    "    max_x = np.max(x)\n",
    "    min_x = np.min(x)\n",
    "    max_y = np.max(y)\n",
    "    min_y = np.min(y)\n",
    "\n",
    "    x = (x-min_x)/max_x\n",
    "    y = (y-min_y)/max_y\n",
    "\n",
    "    ax[0].scatter(x, y, c='b', alpha=0.75)\n",
    "    \n",
    "    exc_norm_x.extend(x)\n",
    "    exc_norm_y.extend(y)\n",
    "    \n",
    "    x = all_n_targ_resp[i:i+100]\n",
    "    y = all_n_s2_exc[i:i+100]\n",
    "    \n",
    "    max_x = np.max(x)\n",
    "    min_x = np.min(x)\n",
    "    max_y = np.max(y)\n",
    "    min_y = np.min(y)\n",
    "\n",
    "    x = (x-min_x)/max_x\n",
    "    y = (y-min_y)/max_y\n",
    "    \n",
    "    ax[1].scatter(x, y, c='r', alpha=0.75)\n",
    "\n",
    "    inh_norm_x.extend(x)\n",
    "    inh_norm_y.extend(y)\n",
    "\n",
    "    i+=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot sta excitation and inhibition in space \n",
    "\n",
    "pkl_folder = r'P:\\rlees\\pkl_files'\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "all_amps = []\n",
    "all_dists = []\n",
    "all_x = []\n",
    "all_y = []\n",
    "\n",
    "for root, dirs, files in os.walk(pkl_folder):\n",
    "    for file in files:\n",
    "        pkl_path = os.path.join(pkl_folder, file)\n",
    "\n",
    "#         if 'spont_sham' in pkl_path:\n",
    "        if any(s in pkl_path for s in ['random', 'sensory']):\n",
    "\n",
    "            print(pkl_path)\n",
    "            \n",
    "            with open(pkl_path, 'rb') as f:\n",
    "                exp_obj = pickle.load(f)\n",
    "\n",
    "            followers = []\n",
    "\n",
    "            for cell in range(exp_obj.n_units[0]):\n",
    "                cell_coord = exp_obj.cell_med[0][cell]\n",
    "\n",
    "                if exp_obj.targeted_cells[cell]==0:\n",
    "                    followers.append(([cell_coord[1],cell_coord[0]], exp_obj.sta_amplitudes[0][cell]))\n",
    "            \n",
    "            tree = spatial.KDTree(exp_obj.target_coords)\n",
    "            \n",
    "            norm_x = []\n",
    "            norm_y = []\n",
    "            amps = []\n",
    "            dists = []\n",
    "\n",
    "            for coord, amp in followers:\n",
    "                dist, index = tree.query(coord)\n",
    "                x,y = np.subtract(coord, exp_obj.target_coords[index])\n",
    "                norm_x.append(x)\n",
    "                norm_y.append(y)\n",
    "                amps.append(amp)         \n",
    "                dists.append(dist)\n",
    "                        \n",
    "            x_um = [x*exp_obj.pix_sz_x for x in norm_x]\n",
    "            y_um = [y*exp_obj.pix_sz_y for y in norm_y]\n",
    "            sc = plt.scatter(x_um, y_um, c=amps, cmap='RdBu_r', vmin=-5, vmax=5, alpha=0.5, linewidth=0)\n",
    "            plt.axis('equal')\n",
    "#             plt.xlim((-150,150))\n",
    "#             plt.ylim((-150,150))\n",
    "            plt.xlabel('Cortical distance (um)')\n",
    "        \n",
    "            all_amps.extend(amps)\n",
    "            all_dists.extend(np.absolute(dists))\n",
    "            all_x.extend(x_um)\n",
    "            all_y.extend(y_um)\n",
    "            \n",
    "cb = plt.colorbar(sc)\n",
    "cb.set_label('dFF %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Want to bin all coordinates in to 10x10 um chunks\n",
    "# Make bins relevant to the max coords? Max x and y\n",
    "# Use np.digitize to get the coords \n",
    "\n",
    "def binned_amplitudes_2d(all_x, all_y, all_amps):\n",
    "    all_amps_real = np.nan_to_num(all_amps)\n",
    "    denominator, xedges, yedges = np.histogram2d(all_x, all_y, bins=50)\n",
    "    nominator, _, _ = np.histogram2d(all_x, all_y, bins=50, weights=all_amps_real)\n",
    "    h = nominator/denominator\n",
    "    Y, X = np.meshgrid(xedges, yedges)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.pcolormesh(X, Y, h, cmap='RdBu_r', vmin=-5, vmax=5)\n",
    "    plt.xlabel('Cortical distance (um)')\n",
    "    \n",
    "    cb = plt.colorbar()\n",
    "    cb.set_label('dFF %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [i for i,amp in enumerate(all_amps) if amp > 0]\n",
    "x = [x for i,x in enumerate(all_x) if i in indices]\n",
    "y = [y for i,y in enumerate(all_y) if i in indices]\n",
    "pos_amps = [amp for i,amp in enumerate(all_amps) if i in indices]\n",
    "\n",
    "binned_amplitudes_2d(x, y, pos_amps)\n",
    "\n",
    "indices = [i for i,amp in enumerate(all_amps) if amp < 0]\n",
    "x = [x for i,x in enumerate(all_x) if i in indices]\n",
    "y = [y for i,y in enumerate(all_y) if i in indices]\n",
    "neg_amps = [amp for i,amp in enumerate(all_amps) if i in indices]\n",
    "\n",
    "binned_amplitudes_2d(x, y, neg_amps)\n",
    "\n",
    "binned_amplitudes_2d(all_x, all_y, all_amps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binned_amplitudes_1d(all_dists,all_amps,bins):\n",
    "    indices = np.digitize(all_dists, bins)\n",
    "\n",
    "    binned_amps = []\n",
    "\n",
    "    for i,_ in enumerate(bins):\n",
    "        binned_dists = np.where(indices == i)[0]\n",
    "\n",
    "        if np.shape(binned_dists)[0] > 0:\n",
    "            amps = [amp for i,amp in enumerate(all_amps) if i in binned_dists]\n",
    "            mean_amp = np.mean(amps)\n",
    "            binned_amps.append(mean_amp)\n",
    "        else:\n",
    "            binned_amps.append(0)\n",
    "    \n",
    "    return binned_amps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(0,700,10)\n",
    "x_um = [x*1.313 for x in x]\n",
    "\n",
    "indices = [i for i,amp in enumerate(all_amps) if amp > 0]\n",
    "dists = [dist for i,dist in enumerate(all_dists) if i in indices]\n",
    "pos_amps = [amp for i,amp in enumerate(all_amps) if i in indices]\n",
    "\n",
    "pos_binned_amps = binned_amplitudes_1d(dists, pos_amps, x)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x_um[2:-10], pos_binned_amps[2:-10], c='r', label = 'excitation')\n",
    "\n",
    "indices = [i for i,amp in enumerate(all_amps) if amp < 0]\n",
    "dists = [dist for i,dist in enumerate(all_dists) if i in indices]\n",
    "neg_amps = [amp for i,amp in enumerate(all_amps) if i in indices]\n",
    "\n",
    "neg_binned_amps = binned_amplitudes_1d(dists, neg_amps, x)\n",
    "\n",
    "plt.plot(x_um[2:-10], neg_binned_amps[2:-10], c='b', label = 'inhibition')\n",
    "\n",
    "sum_amps = np.add(neg_binned_amps, pos_binned_amps)\n",
    "plt.plot(x_um[2:-10], sum_amps[2:-10], c='k', label = 'sum')\n",
    "plt.xlabel('Cortical distance (um)')\n",
    "plt.ylabel('Change in fluorescence (dFF)')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=7, ncols=2, figsize=(10,20))\n",
    "\n",
    "i=0\n",
    "\n",
    "for row in ax:\n",
    "    for col in row:\n",
    "        x = range(100)\n",
    "        y = all_prop_s2_exc[i*100:i*100+100]\n",
    "        col.scatter(x, y, c='r', alpha=.2)\n",
    "        # calc the trendline\n",
    "        z = np.polyfit(x, y, 1)\n",
    "        p = np.poly1d(z)\n",
    "        col.plot(x,p(x),\"r\", lw=2)\n",
    "        col.set_ylim((0,0.2))\n",
    "        \n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "        slope = np.around(slope, decimals=4)\n",
    "        r_value = np.around(r_value, decimals=2)\n",
    "        col.text(70, 0.1, 'Slope: ' + str(slope) + '\\nr: ' + str(r_value)) \n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=7, ncols=2, figsize=(10,20))\n",
    "\n",
    "i=0\n",
    "\n",
    "for row in ax:\n",
    "    for col in row:\n",
    "        x = range(100)\n",
    "        y = all_prop_s2_inh[i*100:i*100+100]\n",
    "        col.scatter(x, y, c='b', alpha=.2)\n",
    "        # calc the trendline\n",
    "        z = np.polyfit(x, y, 1)\n",
    "        p = np.poly1d(z)\n",
    "        col.plot(x,p(x),\"b\", lw=2)\n",
    "        col.set_ylim((0,0.2))\n",
    "        \n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "        slope = np.around(slope, decimals=4)\n",
    "        r_value = np.around(r_value, decimals=2)\n",
    "        col.text(70, 0.1, 'Slope: ' + str(slope) + '\\nr: ' + str(r_value)) \n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=7, ncols=2, figsize=(10,20))\n",
    "\n",
    "i=0\n",
    "\n",
    "for row in ax:\n",
    "    for col in row:\n",
    "        x = range(100)\n",
    "        y = all_prop_targ_resp[i*100:i*100+100]\n",
    "        col.scatter(x, y, c='k', alpha=.2)\n",
    "        # calc the trendline\n",
    "        z = np.polyfit(x, y, 1)\n",
    "        p = np.poly1d(z)\n",
    "        col.plot(x,p(x),\"k\", lw=2)\n",
    "        col.set_ylim((0,1))\n",
    "        \n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "        slope = np.around(slope, decimals=4)\n",
    "        r_value = np.around(r_value, decimals=2)\n",
    "        col.text(70, 0.8, 'Slope: ' + str(slope) + '\\nr: ' + str(r_value)) \n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(exp_obj.mean_img[0], 'gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
